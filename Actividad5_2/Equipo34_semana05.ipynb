{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xq_UEIE1t75y"
   },
   "source": [
    "# **Objetivo de la Actividad**\n",
    "\n",
    "\n",
    "> Trabajar con estos modelos pre-entrenados, generando el vocabulario a partir de tu conjunto de datos de entrenamiento.\n",
    "\n",
    "Para cada palabra de tu vocabulario, podrás sustituirlo por su correspondiente\n",
    "vector continuo. En caso de que no exista el vector para una palabra en particular, se puede eliminar dicha palabra, o bien sustituirla por el vector continuo más cercano.\n",
    "\n",
    "En esta actividad deberás aplicar esta segunda opción.\n",
    "\n",
    "-----\n",
    "\n",
    "*   Existen diversas propuestas para utilizar dichos vectores continuos como entrada para modelos de aprendizaje automático. En particular, en esta actividad cada enunciado será sustituido por el vector promedio de todos los tokens que lo forman.\n",
    "\n",
    "**Modelos:**\n",
    "\n",
    "Modelo de vectores **continuos/embebidos FastText**, es decir, el modelo desarrollado por Facebook en 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3D1AhgmjvJ9C"
   },
   "source": [
    "## **Pregunta 1**\n",
    "\n",
    "Descarga los **3 archivos de Canvas**. En particular, el archivo de datos de **IMDb** ya no requiere transformarse **para obtener sus 1000 registros**. Al cargar los datos de los tres archivos deberás tener un **DataFrame de Pandas de 3000 registros**, con sus etiquetas. Los archivos los encuentras en Canvas y se llaman: **amazon5.txt, imdb5.txt, yelp5.txt.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "tZ_8l4dhwEWV",
    "outputId": "2759246b-9316-46dc-c8ee-dff6378bcd9e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Alberto\n",
      "[nltk_data]     Patraca\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, RegexpStemmer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "5JFdsxNv67X0",
    "outputId": "f871100e-ad5e-44d6-8054-0b3f14506b87"
   },
   "outputs": [],
   "source": [
    "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
    "# !gunzip cc.en.300.vec.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uGjkDFP4vtr"
   },
   "source": [
    "#**Aplicando NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "3nyPbMQ5v7Ly",
    "outputId": "a004dd72-af59-45a6-d205-b809d96b7065"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Alberto\n",
      "[nltk_data]     Patraca\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Alberto\n",
      "[nltk_data]     Patraca\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')        # Tokenizador que ayuda a dividr el texto en enunciados\n",
    "nltk.download('stopwords')    # Acceso a \"stopwords\" en varios idiomas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "uIq_dbSr0EmT",
    "outputId": "729679a0-ee9e-4209-a7a8-970a7772fd57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# Lista de stopwords que se incluyen de manera predeterminada la suite de librerías de NLTK\n",
    "\n",
    "print(len(stopwords.words('english')))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "fzJpjSXPvdRC",
    "outputId": "ca1e4533-83ab-4174-a586-b30b97a25031"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alberto Patraca\\AppData\\Local\\Temp\\ipykernel_24532\\3513401339.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dfi5 = pd.read_csv(url2, sep=' {3,4}', names=['review','label'], header=None, encoding='utf-8')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros de Amazon_5: (1000, 2)\n",
      "Total de registros de IMBD_5: (1000, 2)\n",
      "Total de registros de Yelp_5: (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "#Se extraen los archivos desde repositorio público de GitHub\n",
    "url1 = 'https://raw.githubusercontent.com/Handrum/NLP_EQ_6/main/amazon5.txt'\n",
    "url2 = 'https://raw.githubusercontent.com/Handrum/NLP_EQ_6/main/imdb5.txt'\n",
    "url3 = 'https://raw.githubusercontent.com/Handrum/NLP_EQ_6/main/yelp5.txt'\n",
    "\n",
    "#Se cargan los archivos en dataframe de Pandas\n",
    "dfa5 = pd.read_csv(url1, sep='\\t', names=['review','label'], header=None, encoding='utf-8')\n",
    "dfi5 = pd.read_csv(url2, sep=' {3,4}', names=['review','label'], header=None, encoding='utf-8')\n",
    "dfy5 = pd.read_csv(url3, sep='\\t', names=['review','label'], header=None, encoding='utf-8')\n",
    "\n",
    "#Se imprime la forma de los dataframes\n",
    "print('Total de registros de Amazon_5:',dfa5.shape)\n",
    "print('Total de registros de IMBD_5:',dfi5.shape)\n",
    "print('Total de registros de Yelp_5:',dfy5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "dOAHRDNEz6sY",
    "outputId": "957f62e9-18c8-4e76-ca40-925d4b4668fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  A very, very, very slow-moving, aimless movie ...      0\n",
       "1  Not sure who was more lost - the flat characte...      0\n",
       "2  Attempting artiness with black & white and cle...      0\n",
       "3         Very little music or anything to speak of.      0\n",
       "4  The best scene in the movie was when Gerardo i...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfi5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "CQyhZt_z_rg0",
    "outputId": "75815526-8b4b-4b36-afd3-71a61db89f8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de registros (3000, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   review  3000 non-null   object\n",
      " 1   label   3000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#Concatenar los 3,000 registros\n",
    "\n",
    "df = pd.concat([dfa5, dfi5, dfy5], ignore_index=True)\n",
    "print('Numero de registros',df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6A-W_SItAd_T"
   },
   "source": [
    "Al realizar la revisión del conjunto de datos se observa que el dataset de **imdb5** tiene 1.000 flotantes. Lo que requiere una limpieza especial para dicho dataset. --- **Sin embargo, se encontró que al cargar con el separador correcto, el siguiente paso no es necesario**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "N6dqTvNUIGqG"
   },
   "outputs": [],
   "source": [
    "X = df.review     # Serie de strings\n",
    "Y = df.label      # Serie de enteros 0s y 1s\n",
    "\n",
    "assert X.shape == (3000,)           # verificando que tenemos la dimensiones esperadas.\n",
    "assert Y.shape == (3000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bl9HFj-u4mnk"
   },
   "source": [
    "# **Pregunta 2**\n",
    "\n",
    "Realiza de nuevo un proceso de limpieza. Aplica el preprocesamiento que consideres adecuado, sin embargo, deberás aplicar necesariamente alguna de las técnicas de lematización. Como aplicaremos modelos embebidos pre-entrenados, queremos palabras lo más cercanas a las existentes en un idioma, inglés en este caso. Aplica y justifica cualquier otro proceso de limpieza que consideres\n",
    "adecuado. Recuerda que en esta actividad se usarán vectores embebidos para un problema de clasificación, por lo que deberás tomar de acuerdo a este contexto. Justifica todas las transformaciones que se apliquen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyZ7I3P12JbD"
   },
   "source": [
    "**Procedimiento para quitar las negaciones del conjunto de stopwords en caso de ser necesario**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "OYEURcKY1t-I",
    "outputId": "4c57f3d2-5dda-4d37-b955-3cd3e925264c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "['no', 'nor', 'not', 'ain', 'aren', \"aren't\", 'don', \"don't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "139\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ma']\n"
     ]
    }
   ],
   "source": [
    "# Consideremos la siguiente lista de palabras asociada a negaciones en inglés:\n",
    "\n",
    "mystopwords = stopwords.words('english')\n",
    "\n",
    "negwords = [ 'no', 'nor', 'not', 'ain', 'aren', \"aren't\", 'don', \"don't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "#Se asigna las stopwords de NLTK a mystopwords\n",
    "mystopwords_without_neg = stopwords.words('english')\n",
    "\n",
    "#Se revisa si cada una de las palabras en negwords está presente en mystopwords\n",
    "for word in negwords:\n",
    "    if word in mystopwords_without_neg:\n",
    "      mystopwords_without_neg.remove(word)           # si la palabra está presente, quitarla de la lista\n",
    "\n",
    "#Se imprime la longitud y elementos de negwords para verificar resultados\n",
    "print(len(negwords))\n",
    "print(negwords)\n",
    "\n",
    "#Se imprime la longitud y elementos de los stop words de NLTK para verificar resultados\n",
    "print(len(mystopwords))\n",
    "print(mystopwords)\n",
    "\n",
    "print(len(mystopwords_without_neg))\n",
    "print(mystopwords_without_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDyc80seLI_W"
   },
   "source": [
    "**NOTA**: Es importante tener en cuenta, que en el análisis de sentimientos debemos abarcar el vocabulario suficiente que nos permita entender la opinión del usuario y así mismo identificar aquellas opiniones que puden enriquecer y construir una interacción más amena con el cliente. Para ello, Se considera realizar una depuración de las negaciones que no agregan valor al resultado del diccionario que se requiere y que no definen a profundidad el sentimiento del cliente, estas se pueden ser reemplazadas por un vector continuo más cercano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4XLAEojC5Gbr"
   },
   "outputs": [],
   "source": [
    "def clean_tok(doc):\n",
    "    ##############################################################################\n",
    "    # AGREGA AQUÍ TUS LÍNEAS DE CÓDIGO - Pregunta 4:\n",
    "    \n",
    "    # Eliminación de signos de puntuación, caracteres especiales.\n",
    "    \n",
    "    doc = doc.lower()    #normalización a minúsculas\n",
    "    \n",
    "    #Sólo caracteres alfabéticos\n",
    "    puntuacion = re.sub(r'[^a-z]', ' ', doc)                  #considerar solo caracteres alfabéticos\n",
    "    puntuacion = re.sub(r'\\s{2, }', ' ', puntuacion.strip())  #eliminar todo tipo de espacios que se encuentren\n",
    "    \n",
    "    # Tokenizar\n",
    "    tokenizar = puntuacion.split()                            #tomar el resultado anterior y aplicar método de tokenización a partir del método split\n",
    "    \n",
    "    # Eliminación de Stopwords\n",
    "    \n",
    "    tokens = [token for token in tokenizar if (token not in mystopwords and len(token) >1)]  #en esta ocasión para elimianr los stopwords se toma la librería de corpus el mismo método.\n",
    "    \n",
    "    # FIN PARA AGREGAR TUS LÍNEAS DE CÓDIGO.\n",
    "    ##############################################################################\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hizo la transformación a minúsculas de cada comentario. Posteriormente, se eliminaron los caractéres que no corresponden al afabeto, es decir, cualquier signo de puntuacíon o número, estos se convertían a espacios en blanco \" \"; dejando únicamente las letras de la a la la z en el abecedario inglés (sin ñ).\n",
    "Posteriormente, si en algún lugar quedaba más de un espacio en blanco \" \" seguido, se reducía a únicamente uno.\n",
    "Finalmente, se separaban los tokens de cada comentario, y se eliminaban los tokens que se encontraran en la lista \"mystopwords\" y/o tuvieran solo 1 caracter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "h3cUq1k-LBXt"
   },
   "outputs": [],
   "source": [
    "Xcleantok = [clean_tok(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "QK2ETk5nMCOG",
    "outputId": "e3a3c5e6-cd15-4885-ef77-06ea306c6963"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  So there is no way for me to plug it in here i...      0\n",
       "1                        Good case, Excellent value.      1\n",
       "2                             Great for the jawbone.      1\n",
       "3  Tied to charger for conversations lasting more...      0\n",
       "4                                  The mic is great.      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "lXM_3HnKLIxl",
    "outputId": "a41c7249-d159-4aed-d91c-c1f836c0b523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['way', 'plug', 'us', 'unless', 'go', 'converter']\n",
      "['good', 'case', 'excellent', 'value']\n",
      "['great', 'jawbone']\n",
      "['tied', 'charger', 'conversations', 'lasting', 'minutes', 'major', 'problems']\n",
      "['mic', 'great']\n"
     ]
    }
   ],
   "source": [
    "for x in Xcleantok[0:5]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDs04xbyRyh2"
   },
   "source": [
    "# **Método Limpieza por Lematizazión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "tSMPI-XoSELt",
    "outputId": "8505f8c5-7285-4b2f-cc83-b7158c2f4e3a"
   },
   "outputs": [],
   "source": [
    "#lista vacía para análisis visual\n",
    "palabras = []\n",
    "\n",
    "#ciclo para juntar todos los tokens previos en una lista\n",
    "for tokens1 in Xcleantok:\n",
    "\n",
    "  palabras.extend(tokens1)\n",
    "\n",
    "#Set para eliminar repeticiones\n",
    "dic = set(palabras)\n",
    "\n",
    "#Imprimir resultados para análisis visual\n",
    "#print(sorted(dic))\n",
    "\n",
    "\n",
    "#Se crea un objeto de la clase PorterStemmer\n",
    "#ps = PorterStemmer() #Se requiere usar lematización para utilizar el método de vectores embebidos\n",
    "\n",
    "#Se crea un objeto de la clase WordNetLemmatizer\n",
    "WNL = WordNetLemmatizer()\n",
    "\n",
    "#Definición de la función de limpieza adicional\n",
    "def clean_doc(doc):\n",
    "\n",
    "    #Se define lista vacía para los nuevos tokens\n",
    "    # tokens = stemmer_tokens(doc)\n",
    "    clean_tokens = []\n",
    "    \n",
    "    #Ciclo para la limpieza de los tokens\n",
    "    for token in doc:\n",
    "\n",
    "        no_dups_token = re.sub(r'([a-z])\\1{2,}', r'\\1\\1', token) \n",
    "        # Se aplica un filtro con regex para eliminar palabras donde se repita más de 2 veces seguidas la misma letra\n",
    "\n",
    "        \n",
    "        if len(no_dups_token) == 2 and no_dups_token.endswith('s'):\n",
    "            # Se aplica un filtro para las palabras como \"as\", \"is\", y \"us\", que no se les elimine la \"s\" final por la lematización\n",
    "            clean_tokens.append(no_dups_token)\n",
    "            continue\n",
    "        elif len(no_dups_token) == 3 and no_dups_token.endswith('ed'):\n",
    "            # Se aplica un filtro para las palabras como \"ted\", \"fed\", y \"ned\", que no se les eliminen las \"ed\" finales por la lematización\n",
    "            clean_tokens.append(no_dups_token)\n",
    "            continue\n",
    "        elif len(no_dups_token) == 4 and no_dups_token.endswith('ing'):\n",
    "            # Se aplica un filtro para las palabras como \"ping\", \"bing\", y \"ring\", que no se les eliminen las \"ing\" finales por la lematización\n",
    "            clean_tokens.append(no_dups_token)\n",
    "            continue\n",
    "            \n",
    "        #Se aplica stemming lo cual nos llevará las palabras a su base, incluyendo remover las terminaciones 'ing','ed','s'\n",
    "        #doc[j] = ps.stem(doc[j]) #Se aplica lematización en lugar de stemming\n",
    "    \n",
    "        #Sólo lematizar tokens mas de más de dos caracteres\n",
    "        if len(no_dups_token) < 2:\n",
    "            continue\n",
    "    \n",
    "        #Se intenta lematizar verbo\n",
    "        lem_token = WNL.lemmatize(no_dups_token,'v')\n",
    "        \n",
    "        #Si el token permanece sin cambios, intentar lematizar como sustantivo\n",
    "        if lem_token == no_dups_token:\n",
    "            lem_token = WNL.lemmatize(no_dups_token, 'n')\n",
    "        \n",
    "        #Si el token permanece sin cambios, intentar lematizar como adjetivo\n",
    "        if lem_token == no_dups_token:\n",
    "            lem_token = WNL.lemmatize(no_dups_token,'a')\n",
    "        \n",
    "        #Si el token permanece sin cambios, intentar lematizar como advervio\n",
    "        if lem_token == no_dups_token:\n",
    "            lem_token = WNL.lemmatize(no_dups_token,'r')\n",
    "        \n",
    "        #Agregar el resultado a la lista de tokens límpios (clean_tokens)\n",
    "        clean_tokens.append(lem_token)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí primero se redujeron las letras que pudieran estar repetidas más de 2 veces seguidas en una misma palabra, por ejemplo, en \"doctorrr\", la \"r\" se repite 3 veces seguidas, por lo que nuestro primer paso de limpieza la reduce a únicamente 2, ya que en el idioma inglés, no existe ninguna palabra que tenga una misma letra repetida más de 2 veces continuas.\n",
    "Seguido de eso, se incluyeron condiciones que protegieran palabras de 2 letras que terminaran en \"s\", de 3 letras que terminaran en \"ed\" y de 4 letras que terminaran en \"ing\", ya que la lematización podía transformarlas de maneras inadecuadas.\n",
    "Finalmente, se aplicaba lematización a los tokens previos, en orden de verbo, sustantivo, adjetivo y advervio. La lematización se aplico debido a que hay varias palabras como \"playing\" o \"played\" que tienen la misma base \"play\" y cuya diferenciación, en términos de procesamiento de lenguaje es inservible, nos funciona más definirlas en una misma, tal como \"play\".\n",
    "Aquí culmina nuestra limpieza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "1pIMQaRSSMfd"
   },
   "outputs": [],
   "source": [
    "# Aplicamos el proceso de limpieza/normalización adicionales:\n",
    "\n",
    "Xclean = [clean_doc(x) for x in Xcleantok]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparamos la información antes y después de la limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['way', 'plug', 'us', 'unless', 'go', 'converter'],\n",
       " ['good', 'case', 'excellent', 'value'],\n",
       " ['great', 'jawbone'],\n",
       " ['tied',\n",
       "  'charger',\n",
       "  'conversations',\n",
       "  'lasting',\n",
       "  'minutes',\n",
       "  'major',\n",
       "  'problems'],\n",
       " ['mic', 'great'],\n",
       " ['jiggle', 'plug', 'get', 'line', 'right', 'get', 'decent', 'volume'],\n",
       " ['several',\n",
       "  'dozen',\n",
       "  'several',\n",
       "  'hundred',\n",
       "  'contacts',\n",
       "  'imagine',\n",
       "  'fun',\n",
       "  'sending',\n",
       "  'one',\n",
       "  'one'],\n",
       " ['razr', 'owner', 'must'],\n",
       " ['needless', 'say', 'wasted', 'money'],\n",
       " ['waste', 'money', 'time']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xcleantok[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "F0OxOXN1STP1",
    "outputId": "0f41787f-61a9-4cdc-d03c-43858433042c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['way', 'plug', 'us', 'unless', 'go', 'converter'],\n",
       " ['good', 'case', 'excellent', 'value'],\n",
       " ['great', 'jawbone'],\n",
       " ['tie', 'charger', 'conversation', 'last', 'minute', 'major', 'problem'],\n",
       " ['mic', 'great'],\n",
       " ['jiggle', 'plug', 'get', 'line', 'right', 'get', 'decent', 'volume'],\n",
       " ['several',\n",
       "  'dozen',\n",
       "  'several',\n",
       "  'hundred',\n",
       "  'contact',\n",
       "  'imagine',\n",
       "  'fun',\n",
       "  'send',\n",
       "  'one',\n",
       "  'one'],\n",
       " ['razr', 'owner', 'must'],\n",
       " ['needle', 'say', 'waste', 'money'],\n",
       " ['waste', 'money', 'time']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xclean[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDOBBjn9Wp__"
   },
   "source": [
    "# **Pregunta 3**\n",
    "\n",
    "Llamar Xclean a los comentarios procesados y Y a las etiquetas. Realicemos una partición aleatoria con los mismos porcentajes de la práctica pasada para poder comparar dichos resultados con los de esta actividad, a saber, 70%, 15% y 15%, para entrenamiento, validación y prueba, respectivamente. Verifica que obtienes 2,100 registros de entrenamiento y 450 para cada uno de validación y prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['way', 'plug', 'us', 'unless', 'go', 'converter'],\n",
       " ['good', 'case', 'excellent', 'value'],\n",
       " ['great', 'jawbone'],\n",
       " ['tie', 'charger', 'conversation', 'last', 'minute', 'major', 'problem'],\n",
       " ['mic', 'great'],\n",
       " ['jiggle', 'plug', 'get', 'line', 'right', 'get', 'decent', 'volume'],\n",
       " ['several',\n",
       "  'dozen',\n",
       "  'several',\n",
       "  'hundred',\n",
       "  'contact',\n",
       "  'imagine',\n",
       "  'fun',\n",
       "  'send',\n",
       "  'one',\n",
       "  'one'],\n",
       " ['razr', 'owner', 'must'],\n",
       " ['needle', 'say', 'waste', 'money'],\n",
       " ['waste', 'money', 'time']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xclean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "w88pAxNzX3Zu",
    "outputId": "8a8ad41c-8dfe-4e45-b758-50157807f75d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X,y Train: 2100 2100\n",
      "X,y Val: 450 450\n",
      "X,y Test 450 450\n"
     ]
    }
   ],
   "source": [
    "# Xclean = Comentarios procesados\n",
    "# Y = etiquetas\n",
    "\n",
    "x_train, x_val_and_test, y_train, y_val_and_test = train_test_split(Xclean, Y, train_size=.70, shuffle=True, random_state=1)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val_and_test, y_val_and_test, test_size=.50, shuffle=True, random_state=17)\n",
    "\n",
    "print('X,y Train:', len(x_train), len(y_train))\n",
    "print('X,y Val:', len(x_val), len(y_val))\n",
    "print('X,y Test', len(x_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pregunta 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pregunta 4 A**\n",
    "\n",
    "***Usa el conjunto de entrenamiento para generar tu vocabulario con un tamaño que\n",
    "consideres adecuado. Puedes filtrar tu vocabulario por la frecuencia mínima de uso de cada\n",
    "palabra, así como por su longitud mínima en caracteres.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Definir parámetros de filtrado\n",
    "frecuencia_minima = 2\n",
    "longitud_minima = 2\n",
    "\n",
    "# Contar las palabras en el conjunto de entrenamiento\n",
    "contador_palabras = Counter()\n",
    "for comentario in x_train:\n",
    "    contador_palabras.update(comentario)\n",
    "\n",
    "# Filtrar el vocabulario\n",
    "vocabulario = {palabra: frecuencia for palabra, frecuencia in contador_palabras.items()\n",
    "               if frecuencia >= frecuencia_minima and len(palabra) >= longitud_minima}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pregunta 4 B**\n",
    "\n",
    "**Indica el tamaño del vocabulario generado.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario generado: 1420\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el tamaño del vocabulario generado\n",
    "print(f\"Tamaño del vocabulario generado: {len(vocabulario)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pregunta 4 C**\n",
    "\n",
    "**¿Por qué debe usarse solamente el conjunto de entrenamiento para generar el vocabulario?**\n",
    "\n",
    "Usar solo el conjunto de entrenamiento para generar el vocabulario es importante por las siguientes razones:\n",
    "\n",
    "Evita la fuga de datos (data leakage): La fuga de datos ocurre cuando la información del conjunto de validación o prueba se usa para crear el modelo, lo que puede dar lugar a un rendimiento inflado que no se reflejará en datos nuevos.\n",
    "Representación realista: El vocabulario debe reflejar lo que el modelo encontrará en datos no vistos. Usar solo el conjunto de entrenamiento asegura que el modelo no se adapte específicamente a las características de los conjuntos de validación y prueba.\n",
    "Evaluación justa: Para evaluar de manera justa el rendimiento del modelo, los conjuntos de validación y prueba deben mantenerse independientes de cualquier proceso de modelado que involucre el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pregunta 4 D**\n",
    "\n",
    "\n",
    "**Con el vocabulario generado, filtra los conjuntos de entrenamiento, validación y prueba para\n",
    "que todos los comentarios usen solamente las palabras de este vocabulario.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento filtrado: 2100\n",
      "Tamaño del conjunto de validación filtrado: 450\n",
      "Tamaño del conjunto de prueba filtrado: 450\n"
     ]
    }
   ],
   "source": [
    "def filtrar_comentarios(comentarios, vocabulario):\n",
    "    return [[palabra for palabra in comentario if palabra in vocabulario] for comentario in comentarios]\n",
    "\n",
    "# Filtrar los conjuntos de datos\n",
    "x_train_filtrado = filtrar_comentarios(x_train, vocabulario)\n",
    "x_val_filtrado = filtrar_comentarios(x_val, vocabulario)\n",
    "x_test_filtrado = filtrar_comentarios(x_test, vocabulario)\n",
    "\n",
    "# Verificar el tamaño de los conjuntos filtrados\n",
    "print(f\"Tamaño del conjunto de entrenamiento filtrado: {len(x_train_filtrado)}\")\n",
    "print(f\"Tamaño del conjunto de validación filtrado: {len(x_val_filtrado)}\")\n",
    "print(f\"Tamaño del conjunto de prueba filtrado: {len(x_test_filtrado)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_ySQygSEdcK"
   },
   "source": [
    "# **Pregunta 5**\n",
    "Utilizarás los vectores embebidos FastText preentrenados por Facebook.\n",
    "\n",
    "Incluye una tabla comparativa de pros y contras entre los modelos FastText, word2vec de Google y Glove de Stanford. Puedes consultar sus páginas correspondientes:\n",
    "- https://fasttext.cc/\n",
    "- https://code.google.com/archive/p/word2vec/\n",
    "- https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DD8-dBWo9T9j"
   },
   "source": [
    "| Características | FastText | Word2Vec | GloVe |\n",
    "| ----------- | ----------- | ----------- | ----------- |\n",
    "| **Institución desarrolladora** | Facebook AI | Google | Stanford University |\n",
    "| **Modelo** | Basado en la arquitectura de skip-gram y CBOW | Basado en las arquitecturas de skip-gram y CBOW | Basado en la matriz de co-ocurrencia de palabras en el corpus |\n",
    "| **Manejo de palabras fuera del vocabulario (OOV)** | Buen manejo gracias al uso de n-grams subwords | No lo soporta | No lo soporta |\n",
    "| **Manejo de palabras raras** | Buen manejo gracias al uso de n-grams subwords | Puede tener dificultades con palabras raras | Buen manejo dependiendo de la frecuencia en la matriz de co-ocurrencia |\n",
    "| **Velocidad de entrenamiento** | Media | Rápido | Lento en comparación con FastText y Word2Vec debido al uso de la matriz de co-ocurrencia |\n",
    "| **Dimensiones de los vectores** | Configurable, hasta 300 dimensiones | Configurable, hasta 300 dimensiones | Configurable, hasta 300 dimensiones |\n",
    "| **Requisitos de memoria** | Moderados, debido a los subwords n-grams | Bajos, sólo necesita palabras y contextos | Altos, debido a la matriz de co-ocurrencia |\n",
    "| **Interpretación semántica** | Buena, similar a Word2Vec | Buena, basada en contextos cercanos | Buena, basada en relaciones semánticas y sintácticas |\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Es importante mencionar que cada uno de estos modelos puede ser el más adecuado dependiendo de las necesidades específicas del problema que se esté abordando.\n",
    "\n",
    "Por ejemplo, si necesitas manejar palabras fuera del vocabulario o palabras raras, FastText podría ser la mejor opción; si la memoria es una limitación, Word2Vec podría ser más adecuado; GloVe, por otro lado, podría ser más útil para capturar relaciones semánticas y sintácticas entre palabras.\n",
    "\n",
    "Por otro lado, GloVe podría desempeñarse mejor que Word2Vec para tareas de analogía de palabras, y también muestra un desempeño superior en tareas de similitud y de reconocimiento de nombre de entidades. Mientras que FastText logra un mejor desempeño en tareas sintácticas. Por último, Word2Vec sobrepasa a FastText en tareas semánticas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Bf1J3AiEt-d"
   },
   "source": [
    "# **Pregunta 6**\n",
    "Utiliza el modelo **FastText** de vectores embebidos pre-entrenados de dimensión 300 para generar un nuevo diccionario clave-valor, donde la “clave” será cada token o palabra de tu vocabulario y el “valor” será su vector embebido de dimensión 300. Este diccionario deberá ser del mismo tamaño que el vocabulario previo que hayas construido previamente.\n",
    "https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "\n",
    "**NOTA**: Debido a la cantidad de recursos computacionales que demanda cargar los vectores FastText (son 2 millones de vectores), es recomendable que una vez que generes el nuevo vocabulario de vectores embebidos, guardes dicho diccionario en un archivo (pickle, npz o el que consideres más adecuado). Una vez realizado lo anterior, puedes borrar la variable de FastText para liberar memoria RAM. De esta manera, ya tienes tu vocabulario de vectores embebidos de acuerdo a los tokens que consideras más adecuados para tu problema y puedes usarlo rápidamente\n",
    "cuando lo necesites. En dado caso apóyense entre los miembros del equipo de tener dificultades para generar el vocabulario y por mientras puedes usar el archivo del vocabulario que alguno haya generado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9H3SjaXtFjbJ"
   },
   "source": [
    "**Se instala el módulo de Cython y FastText**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "W8ZJ0jF1EcUq",
    "outputId": "b4cbd8d5-442c-47f8-e892-81230480001b"
   },
   "outputs": [],
   "source": [
    "# !pip install fasttext\n",
    "# !pip install Cython --install-option=\"--no-cython-compile\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QeNah30Fz6T"
   },
   "source": [
    "**Se importa el módulo de fasttext**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "WcwHjBoFF6sl",
    "outputId": "b031ab24-e668-45b9-caf3-e050fa51f3c5"
   },
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "\n",
    "#Se descargan los el modelo de idioma inglés\n",
    "# fasttext.util.download_model('en', if_exists='ignore')  # English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "KWrcylNjJVw4",
    "outputId": "fcfa4952-a72f-4860-8c69-c3250c8949ba"
   },
   "outputs": [],
   "source": [
    "#Se utiliza el modelo FastText de vectores embebidos pre-entrenados de dimensión 300\n",
    "ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Cizy_S4-LDa0",
    "outputId": "6a43a925-62ad-4f33-c6cd-feb164dc738b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del vocabulario de vectores embebidos: 1420\n",
      "Las dimensiones de midicc_vec son: 1420,300\n",
      "[('star', array([-2.86828041e-01,  1.15123533e-01,  5.38213179e-02,  6.26803637e-02,\n",
      "        2.47128960e-02, -2.57342309e-02,  1.47269234e-01, -1.16852485e-01,\n",
      "        1.43789779e-02,  2.02018499e-01, -6.00243136e-02, -6.75183982e-02,\n",
      "       -4.77372715e-03,  4.89413664e-02,  1.16688116e-02, -3.23957461e-03,\n",
      "       -1.23359617e-02, -8.51226449e-02, -4.92033921e-02,  6.35383427e-02,\n",
      "        8.86741839e-03,  1.40952796e-01,  1.09847665e-01,  1.25429276e-02,\n",
      "       -4.25020084e-02, -8.08417723e-02,  2.70867231e-03,  3.24510969e-02,\n",
      "        1.41084492e-02,  1.06206566e-01,  1.08138800e-01, -5.41383438e-02,\n",
      "        5.69636673e-02,  5.37327491e-02, -7.06092343e-02, -9.78406295e-02,\n",
      "       -1.20484188e-01, -4.16465327e-02, -8.21356028e-02,  4.71536033e-02,\n",
      "        9.90687776e-03,  4.89758067e-02, -1.33870468e-01, -1.54928997e-01,\n",
      "       -1.81018680e-01,  1.78726465e-02,  7.79893203e-03, -8.59202892e-02,\n",
      "       -2.29937509e-02, -1.81513757e-01, -1.04256801e-01,  1.19395129e-01,\n",
      "        7.99314678e-03,  5.44246733e-02,  1.18487053e-01,  4.88866717e-02,\n",
      "        5.15220016e-02, -4.63055186e-02,  8.03847145e-03, -5.37553839e-02,\n",
      "       -1.83139741e-02, -9.42408741e-02, -1.01035193e-01,  3.56963836e-02,\n",
      "        1.93327591e-02,  2.09810555e-01,  2.19372492e-02,  2.13999581e-02,\n",
      "        1.16238985e-02, -1.17042363e-01, -1.48543967e-02,  3.18749472e-02,\n",
      "       -1.81292221e-01, -8.17631930e-02,  2.79697850e-02, -3.79535183e-02,\n",
      "        1.45776663e-02,  1.37915611e-01, -8.08674842e-02,  2.51751058e-02,\n",
      "       -6.64169192e-02,  9.05220862e-03,  1.35277987e-01,  2.18077898e-02,\n",
      "        3.70039642e-02, -1.99556798e-02, -1.50145322e-01, -8.03397596e-03,\n",
      "       -7.00799674e-02, -2.94313934e-02, -3.02728191e-02,  1.93609685e-01,\n",
      "        1.89876668e-02, -7.70288929e-02,  1.80713087e-02,  1.10033236e-01,\n",
      "        7.12299794e-02, -4.59963679e-02, -1.72077119e-01,  3.16679366e-02,\n",
      "       -5.98362945e-02, -8.74337852e-02, -8.86409208e-02, -2.87565850e-02,\n",
      "       -5.81971705e-02,  1.01937577e-01,  3.15561742e-02,  1.15741333e-02,\n",
      "       -1.06359929e-01,  1.87610969e-01,  1.45370346e-02,  5.99830151e-02,\n",
      "        9.92235392e-02,  1.91061702e-02, -2.38206740e-02, -2.17346236e-01,\n",
      "        7.70934811e-03, -3.35183665e-02, -1.03727773e-01, -4.16280292e-02,\n",
      "        1.53034225e-01,  8.58682245e-02,  3.14186066e-02,  1.54228285e-01,\n",
      "       -8.03690311e-03,  3.32052186e-02,  4.11878666e-03,  1.05484031e-01,\n",
      "        7.57255778e-02, -3.18720341e-02,  1.70250125e-02,  6.56677261e-02,\n",
      "        1.23368874e-01, -3.03245634e-02,  2.33012419e-02, -1.44071028e-01,\n",
      "        1.45928591e-01,  6.17721789e-02,  1.98618054e-01, -1.88623518e-01,\n",
      "       -6.05288260e-02,  7.98067078e-02,  3.88783626e-02, -1.24917820e-01,\n",
      "       -1.37684941e-01,  6.50793165e-02, -2.99405992e-01, -3.73671472e-04,\n",
      "        4.60229479e-02, -7.02350959e-02, -3.00859064e-02, -1.02555119e-01,\n",
      "       -8.37509986e-03, -3.45986453e-04,  9.31164846e-02, -3.90904620e-02,\n",
      "        1.14622459e-01,  1.26173794e-01,  5.39926952e-03,  2.46864315e-02,\n",
      "       -7.46607184e-02,  6.94717746e-03,  1.56693712e-01, -1.52236253e-01,\n",
      "        3.30955088e-02, -4.14339192e-02, -6.96366578e-02,  9.96302366e-02,\n",
      "       -6.03845380e-02,  9.29320753e-02, -2.12934427e-03, -6.01781867e-02,\n",
      "       -7.10362718e-02, -1.18315414e-01, -6.35388717e-02,  6.41066134e-02,\n",
      "       -5.91891073e-02,  1.27110809e-01,  7.15065151e-02,  6.29523173e-02,\n",
      "       -5.46345413e-02,  2.89074313e-02, -1.59469962e-01, -7.92971104e-02,\n",
      "       -1.03111260e-01, -8.40404853e-02,  6.54209182e-02,  6.68521225e-02,\n",
      "       -2.92568877e-02,  2.20480785e-01,  9.37886834e-02, -9.02144909e-02,\n",
      "       -4.41652164e-02,  8.60180557e-02, -1.45871434e-02,  4.97262180e-02,\n",
      "       -1.41114324e-01,  8.82492661e-02,  9.48378909e-03, -9.70369801e-02,\n",
      "        1.59810316e-02,  1.26596987e-02,  3.80288512e-02,  3.90619189e-02,\n",
      "        9.13637877e-02, -8.60894620e-02,  1.01811588e-01,  6.69082999e-02,\n",
      "        1.05031997e-01,  1.48328632e-01,  6.92542717e-02, -1.06625669e-01,\n",
      "       -1.52740449e-01, -7.56940758e-03,  3.13936025e-02,  3.49867865e-02,\n",
      "       -2.09618788e-02, -1.42902760e-02,  6.80341348e-02,  6.19825125e-02,\n",
      "       -2.84822695e-02,  1.18321627e-01, -1.13135815e-01, -1.77281257e-02,\n",
      "       -5.60616702e-03,  8.14713836e-02, -1.53869148e-02,  8.16864222e-02,\n",
      "       -1.04721271e-01,  1.58673406e-01, -7.53961354e-02,  3.07477619e-02,\n",
      "        9.25838854e-03, -1.48327835e-02,  7.91117456e-03, -3.18586826e-04,\n",
      "       -8.03159773e-02,  6.46696135e-04, -7.53018484e-02, -1.21981822e-01,\n",
      "        4.21633124e-02, -6.28293380e-02, -9.21363831e-02, -5.31597510e-02,\n",
      "        8.62716362e-02, -6.90141022e-02,  2.69403346e-02,  1.61921620e-01,\n",
      "       -4.50303815e-02,  2.98184454e-02, -3.96693758e-05, -7.90106505e-02,\n",
      "       -3.03728543e-02,  1.16063416e-01,  2.34403973e-03,  9.55789983e-02,\n",
      "       -2.87741404e-02, -9.72413719e-02,  3.45763527e-02,  1.02634273e-01,\n",
      "       -2.12719902e-01,  4.99785393e-02, -5.83627820e-02,  1.52304163e-02,\n",
      "       -1.22847423e-01,  4.66357172e-02,  1.46242663e-01,  1.13413274e-01,\n",
      "        1.09998845e-01, -2.39889026e-02,  3.31177339e-02,  4.13419865e-02,\n",
      "       -1.06826507e-01,  4.97730151e-02,  6.61367327e-02, -7.30071217e-02,\n",
      "       -2.99715679e-02,  6.65043890e-02, -5.69159463e-02,  4.16496157e-04,\n",
      "        1.42523021e-01, -4.14542109e-02, -1.05582647e-01, -1.55546203e-01,\n",
      "        6.32830709e-02,  1.06834993e-01, -9.86435339e-02,  7.51124090e-03,\n",
      "       -8.39522183e-02, -1.09830283e-01, -2.86104158e-02,  1.05289333e-01,\n",
      "       -1.09692931e-01,  1.05054498e-01,  1.07300431e-02,  1.82751417e-02,\n",
      "       -4.68385331e-02,  5.67049533e-02, -5.08587807e-03, -1.43625721e-01],\n",
      "      dtype=float32))]\n"
     ]
    }
   ],
   "source": [
    "#Copia de midicc para realizar operaciones\n",
    "midicc_vec = {}\n",
    "\n",
    "#asignar el vector resultante a cada elemento del diccionario\n",
    "for word in vocabulario:\n",
    "    vec_word = ft.get_word_vector(word)\n",
    "    midicc_vec[word] = vec_word\n",
    "\n",
    "print('Longitud del vocabulario de vectores embebidos:', len(midicc_vec))\n",
    "print('Las dimensiones de midicc_vec son: {},{}'.format(len(midicc_vec), len(list(midicc_vec.items())[0][1])))   # veamos algunos elementos del diccionario.\n",
    "print(list(midicc_vec.items())[0:1])     # veamos algunos elementos del diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fasttext\n",
    "# import fasttext.util\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diccionario de vectores embebidos guardado en 'diccionario_vectores.pkl'\n"
     ]
    }
   ],
   "source": [
    "with open('diccionario_vectores.pkl', 'wb') as archivo:\n",
    "    pickle.dump(midicc_vec, archivo)\n",
    "\n",
    "print(\"Diccionario de vectores embebidos guardado en 'diccionario_vectores.pkl'\")\n",
    "\n",
    "# Liberar memoria\n",
    "del ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpRFOjOvwArc"
   },
   "source": [
    "# **Pregunta 7**\n",
    "Una manera de utilizar los vectores embebidos con modelos de aprendizaje automático en\n",
    "documentos de texto, es asignar a cada comentario filtrado el vector embebido de dimensión 300\n",
    "que resulta de promediar todos sus tokens. Así, en este ejercicio deberás generar los arreglos\n",
    "correspondientes para los conjuntos de entrenamiento, validación y prueba. Los llamaremos\n",
    "trainEmb, valEmb y testEmb, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de trainEmb: (2100, 300)\n",
      "Dimensiones de valEmb: (450, 300)\n",
      "Dimensiones de testEmb: (450, 300)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Paso 1: Cargar el diccionario de vectores embebidos\n",
    "with open('diccionario_vectores.pkl', 'rb') as archivo:\n",
    "    diccionario_vectores = pickle.load(archivo)\n",
    "\n",
    "# Paso 2: Definir la función para promediar los vectores embebidos de un comentario\n",
    "def promedio_vectores(comentario, diccionario_vectores, dimension=300):\n",
    "    vectores = [diccionario_vectores[palabra] for palabra in comentario if palabra in diccionario_vectores]\n",
    "    if not len(vectores):\n",
    "        return np.zeros(dimension)\n",
    "    promedio = np.mean(vectores, axis=0)\n",
    "    return promedio\n",
    "\n",
    "# Paso 3: Generar los conjuntos de vectores embebidos promediados\n",
    "trainEmb = np.array([promedio_vectores(comentario, diccionario_vectores) for comentario in x_train_filtrado])\n",
    "valEmb = np.array([promedio_vectores(comentario, diccionario_vectores) for comentario in x_val_filtrado])\n",
    "testEmb = np.array([promedio_vectores(comentario, diccionario_vectores) for comentario in x_test_filtrado])\n",
    "\n",
    "# Verificar las dimensiones de los conjuntos generados\n",
    "print(f\"Dimensiones de trainEmb: {trainEmb.shape}\")\n",
    "print(f\"Dimensiones de valEmb: {valEmb.shape}\")\n",
    "print(f\"Dimensiones de testEmb: {testEmb.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-unf1wrx3aA"
   },
   "source": [
    "# **Pregunta 8**\n",
    "Utiliza los modelos de regresión lineal y bosque aleatorio (random forest) y encuentra sus\n",
    "desempeños (accuracy). Compara los resultados con los de la semana anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "_ByrS1Kvytfg"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100\n",
      "2100\n"
     ]
    }
   ],
   "source": [
    "# Definir rango inicial de hiperparámetros\n",
    "max_depth = [1, 2, 3]\n",
    "max_features = ['sqrt', 'log2', None]\n",
    "n_estimators = [10, 20, 30]\n",
    "criterion = ['gini', 'entropy', 'log_loss']\n",
    "\n",
    "# Crear modelo inicial\n",
    "rf_model = RandomForestClassifier()\n",
    "print(len(trainEmb))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 81 candidates, totalling 486 fits\n",
      "Mejor valor de exactitud obtenido con la mejor combinación: 0.73\n",
      "Mejor combinación de valores encontrados de los hiperparámetros: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 30}\n",
      "Tabla con los resultados de GridSearch para RandomForest:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.137171</td>\n",
       "      <td>0.009025</td>\n",
       "      <td>0.010831</td>\n",
       "      <td>0.004803</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>0.687143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009428</td>\n",
       "      <td>64</td>\n",
       "      <td>0.698571</td>\n",
       "      <td>0.698571</td>\n",
       "      <td>0.682143</td>\n",
       "      <td>0.711429</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.693929</td>\n",
       "      <td>0.016892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.231517</td>\n",
       "      <td>0.012930</td>\n",
       "      <td>0.015105</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>0.655714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023843</td>\n",
       "      <td>58</td>\n",
       "      <td>0.729286</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.731429</td>\n",
       "      <td>0.731429</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.718571</td>\n",
       "      <td>0.725714</td>\n",
       "      <td>0.006481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.327738</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>0.013030</td>\n",
       "      <td>0.005827</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>30</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>0.694286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018749</td>\n",
       "      <td>37</td>\n",
       "      <td>0.731429</td>\n",
       "      <td>0.747857</td>\n",
       "      <td>0.718571</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.734167</td>\n",
       "      <td>0.009551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.091686</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>0.012665</td>\n",
       "      <td>0.003413</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>0.654286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021419</td>\n",
       "      <td>71</td>\n",
       "      <td>0.676429</td>\n",
       "      <td>0.698571</td>\n",
       "      <td>0.677857</td>\n",
       "      <td>0.672143</td>\n",
       "      <td>0.702143</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.687857</td>\n",
       "      <td>0.012542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.162186</td>\n",
       "      <td>0.007171</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>log2</td>\n",
       "      <td>20</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007319</td>\n",
       "      <td>60</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.702857</td>\n",
       "      <td>0.712857</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.701786</td>\n",
       "      <td>0.005467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.370972</td>\n",
       "      <td>0.016433</td>\n",
       "      <td>0.008950</td>\n",
       "      <td>0.007720</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>20</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 3, 'max...</td>\n",
       "      <td>0.697143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017211</td>\n",
       "      <td>14</td>\n",
       "      <td>0.826429</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.801429</td>\n",
       "      <td>0.802857</td>\n",
       "      <td>0.800714</td>\n",
       "      <td>0.793571</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.010379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.564234</td>\n",
       "      <td>0.019636</td>\n",
       "      <td>0.014669</td>\n",
       "      <td>0.006217</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>30</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 3, 'max...</td>\n",
       "      <td>0.717143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011147</td>\n",
       "      <td>3</td>\n",
       "      <td>0.812857</td>\n",
       "      <td>0.799286</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.810714</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.818571</td>\n",
       "      <td>0.812262</td>\n",
       "      <td>0.008159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>5.207267</td>\n",
       "      <td>0.158899</td>\n",
       "      <td>0.003415</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 3, 'max...</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012363</td>\n",
       "      <td>42</td>\n",
       "      <td>0.782857</td>\n",
       "      <td>0.791429</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.777857</td>\n",
       "      <td>0.790357</td>\n",
       "      <td>0.008162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>10.255197</td>\n",
       "      <td>0.230054</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.005605</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 3, 'max...</td>\n",
       "      <td>0.697143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011936</td>\n",
       "      <td>30</td>\n",
       "      <td>0.817143</td>\n",
       "      <td>0.782143</td>\n",
       "      <td>0.799286</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800595</td>\n",
       "      <td>0.010297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>14.192918</td>\n",
       "      <td>0.200733</td>\n",
       "      <td>0.010486</td>\n",
       "      <td>0.007417</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 3, 'max...</td>\n",
       "      <td>0.711429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010519</td>\n",
       "      <td>21</td>\n",
       "      <td>0.808571</td>\n",
       "      <td>0.790714</td>\n",
       "      <td>0.792143</td>\n",
       "      <td>0.802857</td>\n",
       "      <td>0.818571</td>\n",
       "      <td>0.773571</td>\n",
       "      <td>0.797738</td>\n",
       "      <td>0.014389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.137171      0.009025         0.010831        0.004803   \n",
       "1        0.231517      0.012930         0.015105        0.001383   \n",
       "2        0.327738      0.005828         0.013030        0.005827   \n",
       "3        0.091686      0.010332         0.012665        0.003413   \n",
       "4        0.162186      0.007171         0.003984        0.004018   \n",
       "..            ...           ...              ...             ...   \n",
       "76       0.370972      0.016433         0.008950        0.007720   \n",
       "77       0.564234      0.019636         0.014669        0.006217   \n",
       "78       5.207267      0.158899         0.003415        0.002926   \n",
       "79      10.255197      0.230054         0.005654        0.005605   \n",
       "80      14.192918      0.200733         0.010486        0.007417   \n",
       "\n",
       "   param_criterion param_max_depth param_max_features param_n_estimators  \\\n",
       "0             gini               1               sqrt                 10   \n",
       "1             gini               1               sqrt                 20   \n",
       "2             gini               1               sqrt                 30   \n",
       "3             gini               1               log2                 10   \n",
       "4             gini               1               log2                 20   \n",
       "..             ...             ...                ...                ...   \n",
       "76        log_loss               3               log2                 20   \n",
       "77        log_loss               3               log2                 30   \n",
       "78        log_loss               3               None                 10   \n",
       "79        log_loss               3               None                 20   \n",
       "80        log_loss               3               None                 30   \n",
       "\n",
       "                                               params  split0_test_score  ...  \\\n",
       "0   {'criterion': 'gini', 'max_depth': 1, 'max_fea...           0.687143  ...   \n",
       "1   {'criterion': 'gini', 'max_depth': 1, 'max_fea...           0.655714  ...   \n",
       "2   {'criterion': 'gini', 'max_depth': 1, 'max_fea...           0.694286  ...   \n",
       "3   {'criterion': 'gini', 'max_depth': 1, 'max_fea...           0.654286  ...   \n",
       "4   {'criterion': 'gini', 'max_depth': 1, 'max_fea...           0.662857  ...   \n",
       "..                                                ...                ...  ...   \n",
       "76  {'criterion': 'log_loss', 'max_depth': 3, 'max...           0.697143  ...   \n",
       "77  {'criterion': 'log_loss', 'max_depth': 3, 'max...           0.717143  ...   \n",
       "78  {'criterion': 'log_loss', 'max_depth': 3, 'max...           0.678571  ...   \n",
       "79  {'criterion': 'log_loss', 'max_depth': 3, 'max...           0.697143  ...   \n",
       "80  {'criterion': 'log_loss', 'max_depth': 3, 'max...           0.711429  ...   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.009428               64            0.698571            0.698571   \n",
       "1         0.023843               58            0.729286            0.728571   \n",
       "2         0.018749               37            0.731429            0.747857   \n",
       "3         0.021419               71            0.676429            0.698571   \n",
       "4         0.007319               60            0.700000            0.700000   \n",
       "..             ...              ...                 ...                 ...   \n",
       "76        0.017211               14            0.826429            0.810000   \n",
       "77        0.011147                3            0.812857            0.799286   \n",
       "78        0.012363               42            0.782857            0.791429   \n",
       "79        0.011936               30            0.817143            0.782143   \n",
       "80        0.010519               21            0.808571            0.790714   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.682143            0.711429            0.710000   \n",
       "1             0.731429            0.731429            0.715000   \n",
       "2             0.718571            0.735714            0.742857   \n",
       "3             0.677857            0.672143            0.702143   \n",
       "4             0.700000            0.702857            0.712857   \n",
       "..                 ...                 ...                 ...   \n",
       "76            0.801429            0.802857            0.800714   \n",
       "77            0.825000            0.810714            0.807143   \n",
       "78            0.800000            0.790000            0.800000   \n",
       "79            0.799286            0.800000            0.805000   \n",
       "80            0.792143            0.802857            0.818571   \n",
       "\n",
       "    split5_train_score  mean_train_score  std_train_score  \n",
       "0             0.662857          0.693929         0.016892  \n",
       "1             0.718571          0.725714         0.006481  \n",
       "2             0.728571          0.734167         0.009551  \n",
       "3             0.700000          0.687857         0.012542  \n",
       "4             0.695000          0.701786         0.005467  \n",
       "..                 ...               ...              ...  \n",
       "76            0.793571          0.805833         0.010379  \n",
       "77            0.818571          0.812262         0.008159  \n",
       "78            0.777857          0.790357         0.008162  \n",
       "79            0.800000          0.800595         0.010297  \n",
       "80            0.773571          0.797738         0.014389  \n",
       "\n",
       "[81 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kfold= RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=7)\n",
    "\n",
    "rf_params= {'max_depth': max_depth,\n",
    "            'max_features': max_features,\n",
    "            'n_estimators': n_estimators,\n",
    "            'criterion': criterion}\n",
    "\n",
    "rf_grid= GridSearchCV(rf_model, rf_params, scoring='accuracy', cv=kfold, n_jobs=-1, verbose=3, return_train_score=True)\n",
    "rf_grid.fit(trainEmb, y_train)\n",
    "rf_best = rf_grid.best_params_\n",
    "rf_grid_df = pd.DataFrame(rf_grid.cv_results_)\n",
    "\n",
    "print(f'Mejor valor de exactitud obtenido con la mejor combinación: {round(rf_grid.best_score_,2)}')\n",
    "print(f'Mejor combinación de valores encontrados de los hiperparámetros: {rf_best}')\n",
    "print('Tabla con los resultados de GridSearch para RandomForest:')\n",
    "display(rf_grid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud en el conjunto de entrenamiento: 0.785\n",
      "Exactitud en el conjunto de validación: 0.693\n",
      "Exactitud en el conjunto de validación: 0.727\n"
     ]
    }
   ],
   "source": [
    "final_rf_model = RandomForestClassifier(max_depth=rf_best['max_depth'],\n",
    "                                        max_features=rf_best['max_features'],\n",
    "                                        n_estimators=rf_best['n_estimators'],\n",
    "                                        criterion= rf_best['criterion'])\n",
    "final_rf_model.fit(trainEmb, y_train)\n",
    "train_accuracy = final_rf_model.score(trainEmb, y_train)\n",
    "val_accuracy = final_rf_model.score(valEmb, y_val)\n",
    "\n",
    "print(f\"Exactitud en el conjunto de entrenamiento: {train_accuracy:.3f}\")\n",
    "print(f\"Exactitud en el conjunto de validación: {val_accuracy:.3f}\")\n",
    "print(f\"Exactitud en el conjunto de validación: {(final_rf_model.score(testEmb, y_test)):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definir rango inicial de hiperparámetros\n",
    "C = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "solver = ['lbfgs', 'liblinear', 'newton-cholesky', 'newton-cg', 'sag', 'saga']\n",
    "multi_class= ['auto', 'ovr']\n",
    "\n",
    "# Crear modelo inicial\n",
    "lr_model = LogisticRegression(penalty= 'l2', max_iter=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 72 candidates, totalling 432 fits\n",
      "Mejor valor de exactitud obtenido con la mejor combinación: 0.8\n",
      "Mejor combinación de valores encontrados de los hiperparámetros: {'C': 10, 'multi_class': 'auto', 'solver': 'sag'}\n",
      "Tabla con los resultados de GridSearch para LogisticRegression:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053558</td>\n",
       "      <td>0.009030</td>\n",
       "      <td>0.008865</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>0.001</td>\n",
       "      <td>auto</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.001, 'multi_class': 'auto', 'solver': ...</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.060339</td>\n",
       "      <td>0.007085</td>\n",
       "      <td>0.003646</td>\n",
       "      <td>0.005825</td>\n",
       "      <td>0.001</td>\n",
       "      <td>auto</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.001, 'multi_class': 'auto', 'solver': ...</td>\n",
       "      <td>0.511429</td>\n",
       "      <td>0.507143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>61</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.512857</td>\n",
       "      <td>0.512143</td>\n",
       "      <td>0.512857</td>\n",
       "      <td>0.510714</td>\n",
       "      <td>0.512143</td>\n",
       "      <td>0.511786</td>\n",
       "      <td>0.001071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.125670</td>\n",
       "      <td>0.014243</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.001</td>\n",
       "      <td>auto</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>{'C': 0.001, 'multi_class': 'auto', 'solver': ...</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.089253</td>\n",
       "      <td>0.012072</td>\n",
       "      <td>0.003059</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.001</td>\n",
       "      <td>auto</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.001, 'multi_class': 'auto', 'solver': ...</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.253578</td>\n",
       "      <td>0.017336</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>0.001</td>\n",
       "      <td>auto</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 0.001, 'multi_class': 'auto', 'solver': ...</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.508571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.337443</td>\n",
       "      <td>0.022636</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>100</td>\n",
       "      <td>ovr</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100, 'multi_class': 'ovr', 'solver': 'li...</td>\n",
       "      <td>0.772857</td>\n",
       "      <td>0.805714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>17</td>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.880714</td>\n",
       "      <td>0.882857</td>\n",
       "      <td>0.880714</td>\n",
       "      <td>0.891429</td>\n",
       "      <td>0.866429</td>\n",
       "      <td>0.881905</td>\n",
       "      <td>0.008046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.189409</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>100</td>\n",
       "      <td>ovr</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>{'C': 100, 'multi_class': 'ovr', 'solver': 'ne...</td>\n",
       "      <td>0.772857</td>\n",
       "      <td>0.805714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>17</td>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.880714</td>\n",
       "      <td>0.882857</td>\n",
       "      <td>0.880714</td>\n",
       "      <td>0.891429</td>\n",
       "      <td>0.866429</td>\n",
       "      <td>0.881905</td>\n",
       "      <td>0.008046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.215585</td>\n",
       "      <td>0.027948</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>100</td>\n",
       "      <td>ovr</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 100, 'multi_class': 'ovr', 'solver': 'ne...</td>\n",
       "      <td>0.772857</td>\n",
       "      <td>0.805714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>17</td>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.880714</td>\n",
       "      <td>0.882857</td>\n",
       "      <td>0.880714</td>\n",
       "      <td>0.891429</td>\n",
       "      <td>0.866429</td>\n",
       "      <td>0.881905</td>\n",
       "      <td>0.008046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>11.747544</td>\n",
       "      <td>2.601955</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>100</td>\n",
       "      <td>ovr</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 100, 'multi_class': 'ovr', 'solver': 'sag'}</td>\n",
       "      <td>0.772857</td>\n",
       "      <td>0.805714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015644</td>\n",
       "      <td>15</td>\n",
       "      <td>0.888571</td>\n",
       "      <td>0.879286</td>\n",
       "      <td>0.882857</td>\n",
       "      <td>0.879286</td>\n",
       "      <td>0.890714</td>\n",
       "      <td>0.866429</td>\n",
       "      <td>0.881190</td>\n",
       "      <td>0.007886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>14.848371</td>\n",
       "      <td>2.422007</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>100</td>\n",
       "      <td>ovr</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 100, 'multi_class': 'ovr', 'solver': 'sa...</td>\n",
       "      <td>0.775714</td>\n",
       "      <td>0.804286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014602</td>\n",
       "      <td>14</td>\n",
       "      <td>0.888571</td>\n",
       "      <td>0.879286</td>\n",
       "      <td>0.882143</td>\n",
       "      <td>0.879286</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.865714</td>\n",
       "      <td>0.880833</td>\n",
       "      <td>0.007948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.053558      0.009030         0.008865        0.007096   0.001   \n",
       "1        0.060339      0.007085         0.003646        0.005825   0.001   \n",
       "2        0.125670      0.014243         0.001000        0.001415   0.001   \n",
       "3        0.089253      0.012072         0.003059        0.000446   0.001   \n",
       "4        0.253578      0.017336         0.003086        0.005487   0.001   \n",
       "..            ...           ...              ...             ...     ...   \n",
       "67       0.337443      0.022636         0.004678        0.005770     100   \n",
       "68       0.189409      0.005067         0.001662        0.001242     100   \n",
       "69       0.215585      0.027948         0.001411        0.001527     100   \n",
       "70      11.747544      2.601955         0.002277        0.003079     100   \n",
       "71      14.848371      2.422007         0.000777        0.001111     100   \n",
       "\n",
       "   param_multi_class     param_solver  \\\n",
       "0               auto            lbfgs   \n",
       "1               auto        liblinear   \n",
       "2               auto  newton-cholesky   \n",
       "3               auto        newton-cg   \n",
       "4               auto              sag   \n",
       "..               ...              ...   \n",
       "67               ovr        liblinear   \n",
       "68               ovr  newton-cholesky   \n",
       "69               ovr        newton-cg   \n",
       "70               ovr              sag   \n",
       "71               ovr             saga   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'C': 0.001, 'multi_class': 'auto', 'solver': ...           0.508571   \n",
       "1   {'C': 0.001, 'multi_class': 'auto', 'solver': ...           0.511429   \n",
       "2   {'C': 0.001, 'multi_class': 'auto', 'solver': ...           0.508571   \n",
       "3   {'C': 0.001, 'multi_class': 'auto', 'solver': ...           0.508571   \n",
       "4   {'C': 0.001, 'multi_class': 'auto', 'solver': ...           0.508571   \n",
       "..                                                ...                ...   \n",
       "67  {'C': 100, 'multi_class': 'ovr', 'solver': 'li...           0.772857   \n",
       "68  {'C': 100, 'multi_class': 'ovr', 'solver': 'ne...           0.772857   \n",
       "69  {'C': 100, 'multi_class': 'ovr', 'solver': 'ne...           0.772857   \n",
       "70  {'C': 100, 'multi_class': 'ovr', 'solver': 'sag'}           0.772857   \n",
       "71  {'C': 100, 'multi_class': 'ovr', 'solver': 'sa...           0.775714   \n",
       "\n",
       "    split1_test_score  ...  std_test_score  rank_test_score  \\\n",
       "0            0.508571  ...        0.000000               63   \n",
       "1            0.507143  ...        0.001978               61   \n",
       "2            0.508571  ...        0.000000               63   \n",
       "3            0.508571  ...        0.000000               63   \n",
       "4            0.508571  ...        0.000000               63   \n",
       "..                ...  ...             ...              ...   \n",
       "67           0.805714  ...        0.014700               17   \n",
       "68           0.805714  ...        0.014700               17   \n",
       "69           0.805714  ...        0.014700               17   \n",
       "70           0.805714  ...        0.015644               15   \n",
       "71           0.804286  ...        0.014602               14   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0             0.508571            0.508571            0.508571   \n",
       "1             0.510000            0.512857            0.512143   \n",
       "2             0.508571            0.508571            0.508571   \n",
       "3             0.508571            0.508571            0.508571   \n",
       "4             0.508571            0.508571            0.508571   \n",
       "..                 ...                 ...                 ...   \n",
       "67            0.889286            0.880714            0.882857   \n",
       "68            0.889286            0.880714            0.882857   \n",
       "69            0.889286            0.880714            0.882857   \n",
       "70            0.888571            0.879286            0.882857   \n",
       "71            0.888571            0.879286            0.882143   \n",
       "\n",
       "    split3_train_score  split4_train_score  split5_train_score  \\\n",
       "0             0.508571            0.508571            0.508571   \n",
       "1             0.512857            0.510714            0.512143   \n",
       "2             0.508571            0.508571            0.508571   \n",
       "3             0.508571            0.508571            0.508571   \n",
       "4             0.508571            0.508571            0.508571   \n",
       "..                 ...                 ...                 ...   \n",
       "67            0.880714            0.891429            0.866429   \n",
       "68            0.880714            0.891429            0.866429   \n",
       "69            0.880714            0.891429            0.866429   \n",
       "70            0.879286            0.890714            0.866429   \n",
       "71            0.879286            0.890000            0.865714   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.508571         0.000000  \n",
       "1           0.511786         0.001071  \n",
       "2           0.508571         0.000000  \n",
       "3           0.508571         0.000000  \n",
       "4           0.508571         0.000000  \n",
       "..               ...              ...  \n",
       "67          0.881905         0.008046  \n",
       "68          0.881905         0.008046  \n",
       "69          0.881905         0.008046  \n",
       "70          0.881190         0.007886  \n",
       "71          0.880833         0.007948  \n",
       "\n",
       "[72 rows x 25 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_params= {'C': C, \n",
    "            'solver': solver,\n",
    "            'multi_class': multi_class}\n",
    "\n",
    "lr_grid= GridSearchCV(lr_model, lr_params, scoring='accuracy', cv=kfold, n_jobs=-1, verbose=3, return_train_score=True)\n",
    "lr_grid.fit(trainEmb, y_train)\n",
    "lr_best = lr_grid.best_params_\n",
    "lr_grid_df = pd.DataFrame(lr_grid.cv_results_)\n",
    "\n",
    "print(f'Mejor valor de exactitud obtenido con la mejor combinación: {round(lr_grid.best_score_,2)}')\n",
    "print(f'Mejor combinación de valores encontrados de los hiperparámetros: {lr_grid.best_params_}')\n",
    "print('Tabla con los resultados de GridSearch para LogisticRegression:')\n",
    "lr_grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud en el conjunto de entrenamiento: 0.844\n",
      "Exactitud en el conjunto de validación: 0.787\n",
      "Exactitud en el conjunto de validación: 0.807\n"
     ]
    }
   ],
   "source": [
    "lr_best = lr_grid.best_params_\n",
    "\n",
    "final_lr_model = LogisticRegression(C=lr_best['C'], \n",
    "                                    solver=lr_best['solver'],\n",
    "                                    multi_class=lr_best['multi_class'],\n",
    "                                    penalty= 'l2', max_iter=5000)\n",
    "final_lr_model.fit(trainEmb, y_train)\n",
    "train_accuracy = final_lr_model.score(trainEmb, y_train)\n",
    "val_accuracy = final_lr_model.score(valEmb, y_val)\n",
    "\n",
    "print(f\"Exactitud en el conjunto de entrenamiento: {train_accuracy:.3f}\")\n",
    "print(f\"Exactitud en el conjunto de validación: {val_accuracy:.3f}\")\n",
    "print(f\"Exactitud en el conjunto de validación: {(final_lr_model.score(testEmb, y_test)):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Respuesta Pregunta 8***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcHKK4bIb2j-"
   },
   "source": [
    "*Notamos que el modelo de RandomForesat es muy suceptible al sobreentrenamiento, esto debido a la manera en que funciona tanto el modelo en si, como la función de sklearn. El parámetro principal para evitar este sobreentrenamiento, es la máxima profundidad de cada árbol, esto debido a que, dada la oportunidad el modelo buscará la mayor profundidad posible, lo que involucra que las \"ramas\" queden por lo general como \"hojas\", es decir, sean específicas para cierto tipo de parámetros de entrada. Esto genera que, al momento de evaluar, el conjunto de datos de entrenamiento encaje casi al 100%, debido a que con esos datos se crearon las hojas que luego se usan para evaluar, por lo que, si queremos un modelo que no sea tan suceptible a esto, lo mejor es limitarlo a una profundidad de 3. También tiene gran injerencia el tamaño del conjunto de datos.*\n",
    "\n",
    "*Con nuestros modelos, pudimos apreciar que los mejores hiperparámetros para un modelo \"Random Forest\" que evite el sobre entremiento son:\n",
    " {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 30}, obteniendo resultados de 79.9% de exactitud de evaluación con el conjunto de prueba, bajando a 70.7% en el de validación, e incrementando a 72.7% en el de prueba, que no es tanta diferencia para considerarse que el modelo se encuentra severamente sobreentrenado.*\n",
    "\n",
    "*En la otra mano, el modelo de \"LogisticRegression\" tuvo los mejores resultados con los hiperparámetros:\n",
    "{'C': 10, 'multi_class': 'auto', 'solver': 'sag'}, teniendo resultados de 84.4% exactos (4.5% mejor que RandomForest) en la evaluación con conjunto de entrenamiento, y 78.7% con el de validación, y 80.7 con el de prueba, significativamente mejor.*\n",
    "\n",
    "*De igual manera, para ambos modelos se utilizó validación cruzada, ayudando a mejorar la variabilidad de los datos de entrenamiento y validación en el GridSearchCV.\n",
    "\n",
    "*Para finalizar, otro aspecto importante a considerar, es el número de estimadores, estos son, la cantidad de árboles dentro del \"RandomForest\" que se someten a \"votación\" para elegir la clasificación final, nosotros, al limitarlos a 30, tuvimos buenos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3jy454oblEv"
   },
   "source": [
    "# **Pregunta 9**\n",
    "Obtener la matriz de confusión e interpretar sus valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mi_cm(yreal, ypred):\n",
    "    cm = confusion_matrix(yreal, ypred)\n",
    "    txt = ['Verdaderos Negativos\\n(VN)','Falsos Positivos\\n(FP)',\\\n",
    "         'Falsos Negativos\\n(FN)', 'Verdaderos Positivos\\n(VP)']\n",
    "    frecuencia = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
    "    porcentaje = [\"{0:.1%}\".format(value) for value in cm.flatten()/np.sum(cm)]\n",
    "    \n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(txt,frecuencia,porcentaje)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    \n",
    "    ax = sns.heatmap(cm, annot=labels, fmt='', cmap='Spectral', cbar=False)\n",
    "    ax.set(ylabel=\"Etiquetas Reales\", xlabel=\"Etiquetas de Predicción\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mejor modelo RF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-accuracy con el mejor modelo de Random Forest 72.44%\n",
      "\n",
      "Matriz de confusión con el mejor modelo de Random Forest:\n",
      "[[158  58]\n",
      " [ 66 168]]\n",
      "\n",
      "Matriz de confusión con el mejor modelo de Random Forest en proporciones:\n",
      "[[0.35111111 0.12888889]\n",
      " [0.14666667 0.37333333]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Test-accuracy con el mejor modelo de Random Forest %.2f%%' % (100*final_rf_model.score(testEmb, y_test)))\n",
    "\n",
    "pred = final_rf_model.predict(testEmb)\n",
    "print('\\nMatriz de confusión con el mejor modelo de Random Forest:')\n",
    "print(confusion_matrix(y_test, pred, labels=[0,1]))\n",
    "\n",
    "print('\\nMatriz de confusión con el mejor modelo de Random Forest en proporciones:')\n",
    "print(confusion_matrix(y_test, pred, labels=[0,1]) / pred.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-accuracy con el mejor modelo de Regresión Logística: 72.44%\n",
      "\n",
      "Matriz de confusión con el mejor Regresión Logística:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Se imprimen los resultados del conjunto de prueba y las matrices de confusión para cada modelo\n",
    "print('Test-accuracy con el mejor modelo de Regresión Logística: %.2f%%' % (100*final_rf_model.score(testEmb, y_test)))\n",
    "pred1 = final_rf_model.predict(testEmb)\n",
    "print('\\nMatriz de confusión con el mejor Regresión Logística:\\n')\n",
    "mi_cm(y_test, pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mejor modelo LR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-accuracy con el mejor modelo de Logistic Regression 80.67%\n",
      "\n",
      "Matriz de confusión con el mejor modelo de Logistic Regression:\n",
      "[[158  58]\n",
      " [ 66 168]]\n",
      "\n",
      "Matriz de confusión con el mejor modelo de Logistic Regression en proporciones:\n",
      "[[0.35111111 0.12888889]\n",
      " [0.14666667 0.37333333]]\n"
     ]
    }
   ],
   "source": [
    "print('Test-accuracy con el mejor modelo de Logistic Regression %.2f%%' % (100*final_lr_model.score(testEmb, y_test)))\n",
    "\n",
    "pred = final_rf_model.predict(testEmb)\n",
    "print('\\nMatriz de confusión con el mejor modelo de Logistic Regression:')\n",
    "print(confusion_matrix(y_test, pred, labels=[0,1]))\n",
    "\n",
    "print('\\nMatriz de confusión con el mejor modelo de Logistic Regression en proporciones:')\n",
    "print(confusion_matrix(y_test, pred, labels=[0,1]) / pred.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-accuracy con el mejor modelo de Regresión Logística: 80.67%\n",
      "\n",
      "Matriz de confusión con el mejor Regresión Logística:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Test-accuracy con el mejor modelo de Regresión Logística: %.2f%%' % (100*final_lr_model.score(testEmb, y_test)))\n",
    "pred1 = final_lr_model.predict(testEmb)\n",
    "print('\\nMatriz de confusión con el mejor Regresión Logística:\\n')\n",
    "mi_cm(y_test, pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QglSgTQkelAN"
   },
   "source": [
    "*Podemos notar que el modelo de regresión logística tuvo mejores resultados en cuanto a los valores del conjunto de pruebas, obteniendo un 80.67% de exactitud, contra un 72.44%. En cuanto a la distribución de los valores, ambos modelos tuvieron su mayor fortaleza en los Verdaderos Positivos, con un 42.7% y 37.3%, para Regresión Logística y Bosque aleatorio, respectivamente. Siguiendo con los verdaderos negativos; 38% y 35.1%. En donde existen diferencias es en el orden de los Falsos Negativos (9.3% y 14.7%) y Falsos Negativos (10% y 12.9%). Recordemos que en los \"Verdaderos\", más es mejor, mientras que para los \"Falsos\" menos es mejor. Podemos notar que hay bastante preferencia en los verdaderos de amabos modelos, por eso su exactitud es buena, sin embargo, podemos notar que acertamos más a los positivos que a los negativos, tendríamos que checar el tema de las distribuciones de los comentarios, si en el conjuntos de entrenamiento, validación y pruebaa hubo la misma cantidad de comentaraios \"positivos\" a los \"negativos\" o no, ya que eso también influye en los resultados.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4CmKx0z6NNb"
   },
   "source": [
    "# **Pregunta 10**\n",
    "Comenta con tus compañeros de equipo los pasos realizados en esta actividad e incluyan sus conclusiones finales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***FALTA MODIFICAR ESTE COMENTARIO***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGcUa5OhB_oP"
   },
   "source": [
    ">>> *Agregar aquí conclusiones del trabajo*\n",
    "\n",
    "*Dentro de la limpieza realizada se encontraron algunas validaciones que mejoraron el desempeño del modelo dado que no se procesaron ciertos valores o caracteres que no son relevantes para el estudio y alteran el resultado esperado. Posteriormente, se ejecutaron las particiones de los elementos para el desarrollo de los modelos; para ello, se acotaron los caracteres dentro del diccionario del conjunto de entrenamiento dado que se involucraron únicamente palabras relevantes las cuales tienen una mayor cantidad de frecuencia dentro de los datos.*\n",
    "\n",
    "*Luego del preprocesamiento anterior, se inició la validación del modelo **FastText** con el fin de identificar la relación que tienen las palabras que contiene el diccionario definido. Luego de inicializarlo, se desarrollaron las funciones requeridas para obtener el promedio de los vectores y de allí otra función que transforme los documentos a vectores embebidos con el fin de asignarles valores a los vectores e identificar la correlación de cada uno entre ellos.*\n",
    "\n",
    "*Con los procedimientos anteriores, se utilizaron dichos vectores para optimizar los modelos de Random Forest y Linear Regression, obteniendo su desempeño y la validación de estos. Detectando los hiperparámetros requeridos para cada modelo y obteniendo los resultados del desempeño de cada uno. **FastText** permite una mejor predicción dado que asigna una mejor relación entre las palabras que únicamente valores de 1 y 0 para los caracteres obtenidos, distorsionando el valor del desempeño de los modelos.*\n",
    "\n",
    "*Para este caso, el método de transformar el corpus a sus vectores preentrenados embebidos, después de el proceso de limpieza y lematización, para después calcular el promedio de los vectores para cada comentario, resultó en una desempeño menor que el que se obtuvo para el mismo conjunto de datos y el uso de la matriz dispersa por conteo de frecuencias y de tf-idf. Con lo anterior, se pudo comprender el valor de tener cada palabra representada como un elemento de un espacio vectorial para encontrar la relación entre las palabras cercanas, sin embargo, para este caso, el uso del promedio de dichos vectores no resultó superior en exactitud a los resultados logrados con las matrices dispersas. Posiblemente, los resultados se pueden mejorar si emplea una simplificación del comentario diferente al promedio de los vectores, como lo sería un proceso de reducción tomando en cuenta la relación que tiene una palabra con otra.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fK_RJaCNBEoj"
   },
   "source": [
    "##### **Fuentes bibliográficas y de datos:**\n",
    "- https://raw.githubusercontent.com/Handrum/NLP_EQ_6/main/amazon5.txt\n",
    "- https://raw.githubusercontent.com/Handrum/NLP_EQ_6/main/imdb5.txt\n",
    "- https://raw.githubusercontent.com/Handrum/NLP_EQ_6/main/yelp5.txt\n",
    "- https://fasttext.cc/\n",
    "- https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "- https://code.google.com/archive/p/word2vec/\n",
    "- https://nlp.stanford.edu/projects/glove/\n",
    "- https://medium.com/analytics-vidhya/word2vec-glove-fasttext-and-baseline-word-embeddings-step-by-step-d0489c15d10b\n",
    "\n",
    "- Vajjala, S., Majumder, B., Gupta, A., y Surana, H. (2020). Practical Natural Language Processing: A Comprehensive Guide to Building Real-World NLP Systems. O'Reilly. https://learning.oreilly.com/library/view/practical-natural-language/9781492054047/\n",
    "\n",
    "\n",
    "- Khurana, D., Koli, A., Khatter, K., y Singh, S. (2023). Natural language processing: state of the art, current trends and challenges. Multimed Tools Appl 82, 3713–3744. https://link.springer.com/article/10.1007/s11042-022-13428-4Links to an external site.\n",
    "\n",
    "- Falcón Morales, L. E. (2023). Bolsa de palabras: BOW [PDF]. Maestría en Inteligencia Artificial Aplicada. ITESM. Acceso al material Download Acceso al material"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
