{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tecnologico-de-Monterrey-MNA/nlp-2023_Equipo-6/blob/main/Equipo_06_Semana_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xq_UEIE1t75y"
   },
   "source": [
    "#**Objetivo de la Actividad**\n",
    "\n",
    "\n",
    "> Trabajar con estos modelos pre-entrenados, generando el vocabulario a partir de tu conjunto de datos de entrenamiento.\n",
    "\n",
    "Para cada palabra de tu vocabulario, podrás sustituirlo por su correspondiente\n",
    "vector continuo. En caso de que no exista el vector para una palabra en particular, se puede eliminar dicha palabra, o bien sustituirla por el vector continuo más cercano.\n",
    "\n",
    "En esta actividad deberás aplicar esta segunda opción.\n",
    "\n",
    "-----\n",
    "\n",
    "*   Existen diversas propuestas para utilizar dichos vectores continuos como entrada para modelos de aprendizaje automático. En particular, en esta actividad cada enunciado será sustituido por el vector promedio de todos los tokens que lo forman.\n",
    "\n",
    "**Modelos:**\n",
    "\n",
    "Modelo de vectores **continuos/embebidos FastText**, es decir, el modelo desarrollado por Facebook en 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3D1AhgmjvJ9C"
   },
   "source": [
    "##**Pregunta 1**\n",
    "\n",
    "Descarga los **3 archivos de Canvas**. En particular, el archivo de datos de **IMDb** ya no requiere transformarse **para obtener sus 1000 registros**. Al cargar los datos de los tres archivos deberás tener un **DataFrame de Pandas de 3000 registros**, con sus etiquetas. Los archivos los encuentras en Canvas y se llaman: **amazon5.txt, imdb5.txt, yelp5.txt.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "tZ_8l4dhwEWV",
    "outputId": "2759246b-9316-46dc-c8ee-dff6378bcd9e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Alberto\n",
      "[nltk_data]     Patraca\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, RegexpStemmer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "5JFdsxNv67X0",
    "outputId": "f871100e-ad5e-44d6-8054-0b3f14506b87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n",
      "\"gunzip\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    }
   ],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
    "!gunzip cc.en.300.vec.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uGjkDFP4vtr"
   },
   "source": [
    "#**Aplicando NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "3nyPbMQ5v7Ly",
    "outputId": "a004dd72-af59-45a6-d205-b809d96b7065"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Alberto\n",
      "[nltk_data]     Patraca\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Alberto\n",
      "[nltk_data]     Patraca\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')        # Tokenizador que ayuda a dividr el texto en enunciados\n",
    "nltk.download('stopwords')    # Acceso a \"stopwords\" en varios idiomas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "uIq_dbSr0EmT",
    "outputId": "729679a0-ee9e-4209-a7a8-970a7772fd57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# Lista de stopwords que se incluyen de manera predeterminada la suite de librerías de NLTK\n",
    "\n",
    "print(len(stopwords.words('english')))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "fzJpjSXPvdRC",
    "outputId": "ca1e4533-83ab-4174-a586-b30b97a25031"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alberto Patraca\\AppData\\Local\\Temp\\ipykernel_11368\\3513401339.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dfi5 = pd.read_csv(url2, sep=' {3,4}', names=['review','label'], header=None, encoding='utf-8')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros de Amazon_5: (1000, 2)\n",
      "Total de registros de IMBD_5: (1000, 2)\n",
      "Total de registros de Yelp_5: (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "#Se extraen los archivos desde repositorio público de GitHub\n",
    "url1 = 'https://raw.githubusercontent.com/Handrum/NLP_EQ_6/main/amazon5.txt'\n",
    "url2 = 'https://raw.githubusercontent.com/Handrum/NLP_EQ_6/main/imdb5.txt'\n",
    "url3 = 'https://raw.githubusercontent.com/Handrum/NLP_EQ_6/main/yelp5.txt'\n",
    "\n",
    "#Se cargan los archivos en dataframe de Pandas\n",
    "dfa5 = pd.read_csv(url1, sep='\\t', names=['review','label'], header=None, encoding='utf-8')\n",
    "dfi5 = pd.read_csv(url2, sep=' {3,4}', names=['review','label'], header=None, encoding='utf-8')\n",
    "dfy5 = pd.read_csv(url3, sep='\\t', names=['review','label'], header=None, encoding='utf-8')\n",
    "\n",
    "#Se imprime la forma de los dataframes\n",
    "print('Total de registros de Amazon_5:',dfa5.shape)\n",
    "print('Total de registros de IMBD_5:',dfi5.shape)\n",
    "print('Total de registros de Yelp_5:',dfy5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "dOAHRDNEz6sY",
    "outputId": "957f62e9-18c8-4e76-ca40-925d4b4668fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  A very, very, very slow-moving, aimless movie ...      0\n",
       "1  Not sure who was more lost - the flat characte...      0\n",
       "2  Attempting artiness with black & white and cle...      0\n",
       "3         Very little music or anything to speak of.      0\n",
       "4  The best scene in the movie was when Gerardo i...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfi5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "CQyhZt_z_rg0",
    "outputId": "75815526-8b4b-4b36-afd3-71a61db89f8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   review  3000 non-null   object\n",
      " 1   label   3000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#Concatenar los 3,000 registros\n",
    "\n",
    "df = pd.concat([dfa5, dfi5, dfy5], ignore_index=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6A-W_SItAd_T"
   },
   "source": [
    "Al realizar la revisión del conjunto de datos se observa que el dataset de **imdb5** tiene 1.000 flotantes. Lo que requiere una limpieza especial para dicho dataset. --- **Sin embargo, se encontró que al cargar con el separador correcto, el siguiente paso no es necesario**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kryovbUFAF2F"
   },
   "outputs": [],
   "source": [
    "#dfi5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "V1bTBFzOBjes"
   },
   "outputs": [],
   "source": [
    "#no necesario\n",
    "#print(dfi5_c.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1s3xzHiQB0HU"
   },
   "outputs": [],
   "source": [
    "#no necesario con la limpieza anterior\n",
    "#print(df['label'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "txUZL511EdAO"
   },
   "outputs": [],
   "source": [
    "#no necesario con la limpieza anterior\n",
    "#dfii5_l = dfi5.fillna(0)\n",
    "#dfii5_l.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Ci9f44O5GIA1"
   },
   "outputs": [],
   "source": [
    "#No necesario con la limpieza anterior\n",
    "#df = pd.concat([dfa5, dfii5_l, dfy5], ignore_index=True)\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "N6dqTvNUIGqG"
   },
   "outputs": [],
   "source": [
    "X = df.review     # Serie de strings\n",
    "Y = df.label      # Serie de enteros 0s y 1s\n",
    "\n",
    "assert X.shape == (3000,)           # verificando que tenemos la dimensiones esperadas.\n",
    "assert Y.shape == (3000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bl9HFj-u4mnk"
   },
   "source": [
    "#**Pregunta 2**\n",
    "\n",
    "Realiza de nuevo un proceso de limpieza. Aplica el preprocesamiento que consideres adecuado, sin embargo, deberás aplicar necesariamente alguna de las técnicas de lematización. Como aplicaremos modelos embebidos pre-entrenados, queremos palabras lo más cercanas a las existentes en un idioma, inglés en este caso. Aplica y justifica cualquier otro proceso de limpieza que consideres\n",
    "adecuado. Recuerda que en esta actividad se usarán vectores embebidos para un problema de clasificación, por lo que deberás tomar de acuerdo a este contexto. Justifica todas las transformaciones que se apliquen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyZ7I3P12JbD"
   },
   "source": [
    "**Procedimiento para quitar las negaciones del conjunto de stopwords en caso de ser necesario**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "OYEURcKY1t-I",
    "outputId": "4c57f3d2-5dda-4d37-b955-3cd3e925264c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "['no', 'nor', 'not', 'ain', 'aren', \"aren't\", 'don', \"don't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "139\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ma']\n"
     ]
    }
   ],
   "source": [
    "# Consideremos la siguiente lista de palabras asociada a negaciones en inglés:\n",
    "\n",
    "mystopwords = stopwords.words('english')\n",
    "\n",
    "negwords = [ 'no', 'nor', 'not', 'ain', 'aren', \"aren't\", 'don', \"don't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "#Se asigna las stopwords de NLTK a mystopwords\n",
    "mystopwords_without_neg = stopwords.words('english')\n",
    "\n",
    "#Se revisa si cada una de las palabras en negwords está presente en mystopwords\n",
    "for word in negwords:\n",
    "    if word in mystopwords_without_neg:\n",
    "      mystopwords_without_neg.remove(word)           # si la palabra está presente, quitarla de la lista\n",
    "\n",
    "#Se imprime la longitud y elementos de negwords para verificar resultados\n",
    "print(len(negwords))\n",
    "print(negwords)\n",
    "\n",
    "#Se imprime la longitud y elementos de los stop words de NLTK para verificar resultados\n",
    "print(len(mystopwords))\n",
    "print(mystopwords)\n",
    "\n",
    "print(len(mystopwords_without_neg))\n",
    "print(mystopwords_without_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDyc80seLI_W"
   },
   "source": [
    "**NOTA**: Es importante tener en cuenta, que en el análisis de sentimientos debemos abarcar el vocabulario suficiente que nos permita entender la opinión del usuario y así mismo identificar aquellas opiniones que puden enriquecer y construir una interacción más amena con el cliente. Para ello, Se considera realizar una depuración de las negaciones que no agregan valor al resultado del diccionario que se requiere y que no definen a profundidad el sentimiento del cliente, estas se pueden ser reemplazadas por un vector continuo más cercano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4XLAEojC5Gbr"
   },
   "outputs": [],
   "source": [
    "def clean_tok(doc):\n",
    "    ##############################################################################\n",
    "    # AGREGA AQUÍ TUS LÍNEAS DE CÓDIGO - Pregunta 4:\n",
    "    \n",
    "    # Eliminación de signos de puntuación, caracteres especiales.\n",
    "    \n",
    "    doc = doc.lower()    #normalización a minúsculas\n",
    "    \n",
    "    #Sólo caracteres alfabéticos\n",
    "    puntuacion = re.sub(r'[^a-z]', ' ', doc)                  #considerar solo caracteres alfabéticos\n",
    "    puntuacion = re.sub(r'\\s{2, }', ' ', puntuacion.strip())  #eliminar todo tipo de espacios que se encuentren\n",
    "    \n",
    "    # Tokenizar\n",
    "    tokenizar = puntuacion.split()                            #tomar el resultado anterior y aplicar método de tokenización a partir del método split\n",
    "    \n",
    "    # Eliminación de Stopwords\n",
    "    \n",
    "    tokens = [token for token in tokenizar if (token not in mystopwords and len(token) >1)]  #en esta ocasión para elimianr los stopwords se toma la librería de corpus el mismo método.\n",
    "    \n",
    "    # FIN PARA AGREGAR TUS LÍNEAS DE CÓDIGO.\n",
    "    ##############################################################################\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "h3cUq1k-LBXt"
   },
   "outputs": [],
   "source": [
    "Xcleantok = [clean_tok(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "QK2ETk5nMCOG",
    "outputId": "e3a3c5e6-cd15-4885-ef77-06ea306c6963"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  So there is no way for me to plug it in here i...      0\n",
       "1                        Good case, Excellent value.      1\n",
       "2                             Great for the jawbone.      1\n",
       "3  Tied to charger for conversations lasting more...      0\n",
       "4                                  The mic is great.      1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "lXM_3HnKLIxl",
    "outputId": "a41c7249-d159-4aed-d91c-c1f836c0b523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['way', 'plug', 'us', 'unless', 'go', 'converter']\n",
      "['good', 'case', 'excellent', 'value']\n",
      "['great', 'jawbone']\n",
      "['tied', 'charger', 'conversations', 'lasting', 'minutes', 'major', 'problems']\n",
      "['mic', 'great']\n"
     ]
    }
   ],
   "source": [
    "for x in Xcleantok[0:5]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDs04xbyRyh2"
   },
   "source": [
    "#**Método Limpieza por Lematizazión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "tSMPI-XoSELt",
    "outputId": "8505f8c5-7285-4b2f-cc83-b7158c2f4e3a"
   },
   "outputs": [],
   "source": [
    "#lista vacía para análisis visual\n",
    "palabras = []\n",
    "\n",
    "#ciclo para juntar todos los tokens previos en una lista\n",
    "for tokens1 in Xcleantok:\n",
    "\n",
    "  palabras.extend(tokens1)\n",
    "\n",
    "#Set para eliminar repeticiones\n",
    "dic = set(palabras)\n",
    "\n",
    "#Imprimir resultados para análisis visual\n",
    "#print(sorted(dic))\n",
    "\n",
    "\n",
    "#Se crea un objeto de la clase PorterStemmer\n",
    "#ps = PorterStemmer() #Se requiere usar lematización para utilizar el método de vectores embebidos\n",
    "\n",
    "#Se crea un objeto de la clase WordNetLemmatizer\n",
    "WNL = WordNetLemmatizer()\n",
    "\n",
    "#Definición de la función de limpieza adicional\n",
    "def clean_doc(doc):\n",
    "\n",
    "    #Se define lista vacía para los nuevos tokens\n",
    "    # tokens = stemmer_tokens(doc)\n",
    "    clean_tokens = []\n",
    "    \n",
    "    #Ciclo para la limpieza de los tokens\n",
    "    for token in doc:\n",
    "\n",
    "        no_dups_token = re.sub(r'([a-z])\\1{2,}', r'\\1\\1', token) \n",
    "        # Se aplica un filtro con regex para eliminar palabras donde se repita más de 2 veces seguidas la misma letra\n",
    "\n",
    "        \n",
    "        if len(no_dups_token) == 2 and no_dups_token.endswith('s'):\n",
    "            # Se aplica un filtro para las palabras como \"as\", \"is\", y \"us\", que no se les elimine la \"s\" final por la lematización\n",
    "            clean_tokens.append(no_dups_token)\n",
    "            continue\n",
    "        elif len(no_dups_token) == 3 and no_dups_token.endswith('ed'):\n",
    "            # Se aplica un filtro para las palabras como \"ted\", \"fed\", y \"ned\", que no se les eliminen las \"ed\" finales por la lematización\n",
    "            clean_tokens.append(no_dups_token)\n",
    "            continue\n",
    "        elif len(no_dups_token) == 4 and no_dups_token.endswith('ing'):\n",
    "            # Se aplica un filtro para las palabras como \"ping\", \"bing\", y \"ring\", que no se les eliminen las \"ing\" finales por la lematización\n",
    "            clean_tokens.append(no_dups_token)\n",
    "            continue\n",
    "            \n",
    "        #Se aplica stemming lo cual nos llevará las palabras a su base, incluyendo remover las terminaciones 'ing','ed','s'\n",
    "        #doc[j] = ps.stem(doc[j]) #Se aplica lematización en lugar de stemming\n",
    "    \n",
    "        #Sólo lematizar tokens mas de más de dos caracteres\n",
    "        if len(token) < 2:\n",
    "            continue\n",
    "    \n",
    "        #Se intenta lematizar verbo\n",
    "        lem_token = WNL.lemmatize(token,'v')\n",
    "        \n",
    "        #Si el token permanece sin cambios, intentar lematizar como sustantivo\n",
    "        if lem_token == no_dups_token:\n",
    "            lem_token = WNL.lemmatize(token, 'n')\n",
    "        \n",
    "        #Si el token permanece sin cambios, intentar lematizar como adjetivo\n",
    "        if lem_token == no_dups_token:\n",
    "            lem_token = WNL.lemmatize(token,'a')\n",
    "        \n",
    "        #Si el token permanece sin cambios, intentar lematizar como advervio\n",
    "        if lem_token == no_dups_token:\n",
    "            lem_token = WNL.lemmatize(token,'r')\n",
    "        \n",
    "        #Agregar el resultado a la lista de tokens límpios (clean_tokens)\n",
    "        clean_tokens.append(lem_token)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "1pIMQaRSSMfd"
   },
   "outputs": [],
   "source": [
    "# Aplicamos el proceso de limpieza/normalización adicionales:\n",
    "\n",
    "Xclean = [clean_doc(x) for x in Xcleantok]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparamos la información antes y después de la limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['way', 'plug', 'us', 'unless', 'go', 'converter'],\n",
       " ['good', 'case', 'excellent', 'value'],\n",
       " ['great', 'jawbone'],\n",
       " ['tied',\n",
       "  'charger',\n",
       "  'conversations',\n",
       "  'lasting',\n",
       "  'minutes',\n",
       "  'major',\n",
       "  'problems'],\n",
       " ['mic', 'great'],\n",
       " ['jiggle', 'plug', 'get', 'line', 'right', 'get', 'decent', 'volume'],\n",
       " ['several',\n",
       "  'dozen',\n",
       "  'several',\n",
       "  'hundred',\n",
       "  'contacts',\n",
       "  'imagine',\n",
       "  'fun',\n",
       "  'sending',\n",
       "  'one',\n",
       "  'one'],\n",
       " ['razr', 'owner', 'must'],\n",
       " ['needless', 'say', 'wasted', 'money'],\n",
       " ['waste', 'money', 'time']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xcleantok[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "F0OxOXN1STP1",
    "outputId": "0f41787f-61a9-4cdc-d03c-43858433042c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['way', 'plug', 'us', 'unless', 'go', 'converter'],\n",
       " ['good', 'case', 'excellent', 'value'],\n",
       " ['great', 'jawbone'],\n",
       " ['tie', 'charger', 'conversation', 'last', 'minute', 'major', 'problem'],\n",
       " ['mic', 'great'],\n",
       " ['jiggle', 'plug', 'get', 'line', 'right', 'get', 'decent', 'volume'],\n",
       " ['several',\n",
       "  'dozen',\n",
       "  'several',\n",
       "  'hundred',\n",
       "  'contact',\n",
       "  'imagine',\n",
       "  'fun',\n",
       "  'send',\n",
       "  'one',\n",
       "  'one'],\n",
       " ['razr', 'owner', 'must'],\n",
       " ['needle', 'say', 'waste', 'money'],\n",
       " ['waste', 'money', 'time']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xclean[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDOBBjn9Wp__"
   },
   "source": [
    "#**Pregunta 3**\n",
    "\n",
    "Llamar Xclean a los comentarios procesados y Y a las etiquetas. Realicemos una partición aleatoria con los mismos porcentajes de la práctica pasada para poder comparar dichos resultados con los de esta actividad, a saber, 70%, 15% y 15%, para entrenamiento, validación y prueba, respectivamente. Verifica que obtienes 2,100 registros de entrenamiento y 450 para cada uno de validación y prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "w88pAxNzX3Zu",
    "outputId": "8a8ad41c-8dfe-4e45-b758-50157807f75d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X,y Train: 2100 2100\n",
      "X,y Val: 450 450\n",
      "X,y Test 450 450\n"
     ]
    }
   ],
   "source": [
    "# Xclean = Comentarios procesados\n",
    "# Y = etiquetas\n",
    "\n",
    "x_train, x_val_and_test, y_train, y_val_and_test = train_test_split(Xclean, Y, train_size=.70, shuffle=True, random_state=1)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val_and_test, y_val_and_test, test_size=.50, shuffle=True, random_state=17)\n",
    "\n",
    "print('X,y Train:', len(x_train), len(y_train))\n",
    "print('X,y Val:', len(x_val), len(y_val))\n",
    "print('X,y Test', len(x_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gq3yjgMbYtmG"
   },
   "source": [
    "# **Pregunta 4**\n",
    "\n",
    "- Usando el conjunto de entrenamiento genera un vocabulario que no sea mayor a 1,500 palabras, ni menor a 1,000.\n",
    "\n",
    ">> **¿Por qué es importante acotar un vocabulario inferior y superiormente? ¿Por qué debe usarse solamente el conjunto de entrenamiento para generar el diccionario?**\n",
    "\n",
    ">>*Se acota el vocabulario porque se emplean las palabras que sólo aportan valor al análisis del corpus, generalmente las que tienen mayor frecuencia de aparición. Se emplea únicamente el diccionario del conjunto de entrenamiento para evitar el filtrado de información cuando se verifica el desempeño del modelo en los conjuntos de validación y prueba. Solamente estarán disponibles los elementos del diccionario del conjunto de entrenamiento para realizar las predicciones en los conjuntos posteriores.*\n",
    "\n",
    "- Con este vocabulario que obtienes, filtra los conjuntos de entrenamiento, validación y prueba, de esta manera todos los comentarios usarán solamente palabras válidas de acuerdo a este vocabulario.\n",
    "\n",
    "- Indica el tamaño del vocabulario obtenido.\n",
    "\n",
    "- Hasta este punto básicamente has realizado transformaciones muy análogas a las de la semana pasada y que son válidas para muchos de los procesos dentro del análisis de textos.\n",
    "\n",
    "- En dado caso comenta con tus compañeros de equipo qué diferencias has observado. Veamos ahora la diferencia con respecto a las matrices Tf-idf que aplicaste la semana pasada, con respecto a los vectores **preentrenados embebidos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "-_cb3UzBwtVb",
    "outputId": "465dd971-87a8-4b52-a121-8384dfc9c6d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del diccionario: 3237\n",
      "\n",
      "(word,frequency):\n",
      "[('good', 202), ('great', 141), ('movie', 140), ('phone', 134), ('film', 130), ('work', 113), ('bad', 112), ('like', 101), ('time', 101), ('one', 100)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/uElEQVR4nO3de3wU1cH/8W8CZAUlCQGSEAkIqKByEVFiFCkUykVFeaRPFbGCUlALVMEqRisCtg1qa62K8utThfqUi5cKKiqWO14CFSQiItEgCgoBBJNwDYGc3x/z7GY32U2ym92dSfJ5v17z2t25nplsMt+cOXMmxhhjBAAA4CCxdhcAAACgIgIKAABwHAIKAABwHAIKAABwHAIKAABwHAIKAABwHAIKAABwHAIKAABwnMZ2FyAUZWVl2rNnj5o3b66YmBi7iwMAAGrAGKPDhw8rLS1NsbFV15HUyYCyZ88epaen210MAAAQgt27d6tt27ZVzlMnA0rz5s0lWTsYHx9vc2kAAEBNFBcXKz093XMer0qdDCjuyzrx8fEEFAAA6piaNM+gkSwAAHAcAgoAAHAcAgoAAHAcAgoAAHAcAgoAAHAcAgoAAHAcAgoAAHAcAgoAAHAcAgoAAHAcAgoAAHAcAgoAAHAcAgoAAHAcAkoFGzZIzz4rGWN3SQAAaLiCCijZ2dm67LLL1Lx5cyUnJ2v48OHKy8vzmefEiROaMGGCWrZsqbPOOksjRozQvn37fObZtWuXrrnmGjVr1kzJycm67777dOrUqdrvTRhcfrk0aZL0+ut2lwQAgIYrqICydu1aTZgwQevXr9fy5ctVWlqqQYMG6ejRo555Jk+erLfeekuvvvqq1q5dqz179uiGG27wTD99+rSuueYanTx5Uh999JH+8Y9/aN68eZo2bVr49ioMtm+3uwQAADRcMcaEfjHjwIEDSk5O1tq1a9W3b18VFRWpdevWWrBggX7+859LkrZv364LLrhAOTk5uvzyy/Xuu+/q2muv1Z49e5SSkiJJmjNnjqZOnaoDBw4oLi6u2u0WFxcrISFBRUVFio+PD7X4fsXEWK+//7300ENhXTUAAA1aMOfvWrVBKSoqkiQlJSVJkjZt2qTS0lINHDjQM0+XLl3Url075eTkSJJycnLUrVs3TziRpMGDB6u4uFiff/653+2UlJSouLjYZwAAAPVXyAGlrKxM99xzj6688kp17dpVklRQUKC4uDglJib6zJuSkqKCggLPPN7hxD3dPc2f7OxsJSQkeIb09PRQiw0AAOqAkAPKhAkTtHXrVi1atCic5fErKytLRUVFnmH37t0R3yYAALBP41AWmjhxopYuXap169apbdu2nvGpqak6efKkCgsLfWpR9u3bp9TUVM88//nPf3zW577Lxz1PRS6XSy6XK5SiAgCAOiioGhRjjCZOnKjFixdr1apV6tChg8/0Xr16qUmTJlq5cqVnXF5ennbt2qXMzExJUmZmpj777DPt37/fM8/y5csVHx+vCy+8sDb7AgAA6omgalAmTJigBQsW6I033lDz5s09bUYSEhLUtGlTJSQkaOzYsZoyZYqSkpIUHx+vSZMmKTMzU5dffrkkadCgQbrwwgv1y1/+Uo8//rgKCgr0u9/9ThMmTKCWBAAASAoyoDz//POSpH79+vmMnzt3rsaMGSNJ+stf/qLY2FiNGDFCJSUlGjx4sJ577jnPvI0aNdLSpUt11113KTMzU2eeeaZGjx6tmTNn1m5PAABAvVGrflDsQj8oAADUPVHrBwUAACASCCgAAMBxCCgAAMBxCCgAAMBxCCgAAMBxCCgBuO/mAQAA0UdACaDu3XwNAED9QUABAACOQ0ABAACOQ0ABAACOQ0ABAACOQ0ABAACOQ0ABAACOQ0AJgH5QAACwDwElAPpBAQDAPgQUAADgOAQUAADgOAQUAADgOAQUAADgOAQUAADgOASUALjNGAAA+xBQAACA4xBQAqAfFAAA7ENAAQAAjkNAAQAAjkNAAQAAjkNAAQAAjkNAAQAAjkNACYB+UAAAsA8BBQAAOE7QAWXdunUaNmyY0tLSFBMToyVLlvhMj4mJ8Ts88cQTnnnOOeecStNnzZpV650BAAD1Q9AB5ejRo+rRo4dmz57td/revXt9hhdffFExMTEaMWKEz3wzZ870mW/SpEmh7UGE0FEbAAD2aRzsAkOHDtXQoUMDTk9NTfX5/MYbb6h///7q2LGjz/jmzZtXmhcAAECKcBuUffv26e2339bYsWMrTZs1a5Zatmypnj176oknntCpU6ciWRQAAFCHBF2DEox//OMfat68uW644Qaf8b/5zW90ySWXKCkpSR999JGysrK0d+9ePfnkk37XU1JSopKSEs/n4uLiSBYbAADYLKIB5cUXX9SoUaN0xhln+IyfMmWK53337t0VFxenO+64Q9nZ2XK5XJXWk52drRkzZkSyqJVwmzEAAPaJ2CWe999/X3l5efrVr35V7bwZGRk6deqUvvnmG7/Ts7KyVFRU5Bl2794d5tICAAAniVgNygsvvKBevXqpR48e1c6bm5ur2NhYJScn+53ucrn81qwAAID6KeiAcuTIEeXn53s+79y5U7m5uUpKSlK7du0kWW1EXn31Vf35z3+utHxOTo42bNig/v37q3nz5srJydHkyZN1yy23qEWLFrXYFQAAUF8EHVA2btyo/v37ez6725OMHj1a8+bNkyQtWrRIxhiNHDmy0vIul0uLFi3S9OnTVVJSog4dOmjy5Mk+7VKcgH5QAACwT4wxde9UXFxcrISEBBUVFSk+Pj6s63Y3jv3976WHHgrrqgEAaNCCOX/zLB4AAOA4BBQAAOA4BJQA6AcFAAD7EFAAAIDjEFAAAIDjEFAAAIDjEFACqHs3XwMAUH8QUAAAgOMQUAAAgOMQUAAAgOMQUAKgHxQAAOxDQAEAAI5DQAEAAI5DQAEAAI5DQAmAflAAALAPAQUAADgOAQUAADgOASUAbjMGAMA+BBQAAOA4BBQAAOA4BBQAAOA4BBQAAOA4BBQAAOA4BJQA6KgNAAD7EFAAAIDjEFACoB8UAADsQ0ABAACOQ0ABAACOQ0ABAACOQ0ABAACOQ0ABAACOE3RAWbdunYYNG6a0tDTFxMRoyZIlPtPHjBmjmJgYn2HIkCE+8xw6dEijRo1SfHy8EhMTNXbsWB05cqRWOwIAAOqPoAPK0aNH1aNHD82ePTvgPEOGDNHevXs9w8KFC32mjxo1Sp9//rmWL1+upUuXat26dRo/fnzwpQcAAPVS42AXGDp0qIYOHVrlPC6XS6mpqX6nffHFF1q2bJk+/vhjXXrppZKkZ555RldffbX+9Kc/KS0tLdgiAQCAeiYibVDWrFmj5ORkde7cWXfddZcOHjzomZaTk6PExERPOJGkgQMHKjY2Vhs2bPC7vpKSEhUXF/sMAACg/gp7QBkyZIheeuklrVy5Uo899pjWrl2roUOH6vTp05KkgoICJScn+yzTuHFjJSUlqaCgwO86s7OzlZCQ4BnS09PDXWwAAOAgQV/iqc5NN93ked+tWzd1795dnTp10po1azRgwICQ1pmVlaUpU6Z4PhcXFxNSAACoxyJ+m3HHjh3VqlUr5efnS5JSU1O1f/9+n3lOnTqlQ4cOBWy34nK5FB8f7zMAAID6K+IB5bvvvtPBgwfVpk0bSVJmZqYKCwu1adMmzzyrVq1SWVmZMjIyIl0cAABQBwR9iefIkSOe2hBJ2rlzp3Jzc5WUlKSkpCTNmDFDI0aMUGpqqnbs2KH7779f5557rgYPHixJuuCCCzRkyBCNGzdOc+bMUWlpqSZOnKibbrqJO3gAAICkEGpQNm7cqJ49e6pnz56SpClTpqhnz56aNm2aGjVqpC1btui6667T+eefr7Fjx6pXr156//335XK5POuYP3++unTpogEDBujqq69Wnz599Le//S18ewUAAOq0oGtQ+vXrJ2NMwOnvvfdetetISkrSggULgt00AABoIHgWDwAAcBwCCgAAcBwCCgAAcBwCCgAAcBwCCgAAcBwCSgAxMXaXAACAhouAEkAVd1IDAIAII6AEacUK6Zln7C4FAAD1W9ifZlzf/exn1muPHlLfvvaWBQCA+ooalBpYuFC6+GLJ6xFE+vZb24oDAEC9Rw1KDdx8s/U6bpy95QAAoKGgBiUIR47YXQIAABoGAgoAAHAcAkoA1fWDwm3IAABEDgElAAIIAAD2IaAEwbtWhZ5mAQCIHAJKEKhVAQAgOggoAADAcQgoIaI2BQCAyCGgBCGYdierV0u9e0ubN0euPAAA1Ff0JBshP/2p9Tp4sLR/v71lAQCgrqEGJYDqaktqWpty8GDtywIAQENDQAmANiYAANiHgBIiAgwAAJFDQAEAAI5DQKkFY6Tvv7e7FAAA1D8ElFqYOVNq21Z6/HG7SwIAQP1CQKmF6dOt16lTbS0GAAD1DgElAB4GCACAfQgoAADAcQgoAADAcYIOKOvWrdOwYcOUlpammJgYLVmyxDOttLRUU6dOVbdu3XTmmWcqLS1Nt956q/bs2eOzjnPOOUcxMTE+w6xZs2q9M+FEPycAANgn6IBy9OhR9ejRQ7Nnz6407dixY/rkk0/08MMP65NPPtHrr7+uvLw8XXfddZXmnTlzpvbu3esZJk2aFNoeRBHtUgAAiI6gHxY4dOhQDR061O+0hIQELV++3Gfcs88+q969e2vXrl1q166dZ3zz5s2Vmpoa7OYBAEADEPE2KEVFRYqJiVFiYqLP+FmzZqlly5bq2bOnnnjiCZ06dSrgOkpKSlRcXOwz2IHLPgAAREfQNSjBOHHihKZOnaqRI0cqPj7eM/43v/mNLrnkEiUlJemjjz5SVlaW9u7dqyeffNLverKzszVjxoxIFhUAADhIxAJKaWmpfvGLX8gYo+eff95n2pQpUzzvu3fvrri4ON1xxx3Kzs6Wy+WqtK6srCyfZYqLi5Wenh6pokvy396ENigAAERHRAKKO5x8++23WrVqlU/tiT8ZGRk6deqUvvnmG3Xu3LnSdJfL5Te42InLPQAARE7YA4o7nHz11VdavXq1WrZsWe0yubm5io2NVXJycriLAwAA6qCgA8qRI0eUn5/v+bxz507l5uYqKSlJbdq00c9//nN98sknWrp0qU6fPq2CggJJUlJSkuLi4pSTk6MNGzaof//+at68uXJycjR58mTdcsstatGiRfj2rJaqqyHhcg8AAJETdEDZuHGj+vfv7/nsbhsyevRoTZ8+XW+++aYk6eKLL/ZZbvXq1erXr59cLpcWLVqk6dOnq6SkRB06dNDkyZN92pgAAICGLeiA0q9fP5kqqheqmiZJl1xyidavXx/sZgEAQAPCs3hCRCNZAAAih4ASQLjamNBWBQCA4BFQghBK2KCmBQCA4BFQQkTNCAAAkUNACQK1IQAARAcBJYDqwghhBQCAyCGgAAAAxyGgBCGUdie0VQEAIHgElAjjUhAAAMEjoARQXc0HNSMAAEQOASVE1IwAABA5BBQAAOA4BJQIC/VS0ObN0vDh0rZtYS0OAAB1QtBPM0Z0XH65dPKk9PHHUn6+1LSp3SUCACB6qEEJIFxtTEJdz8mT1uuePVKzZtKSJeEpDwAAdQEBJQh23rlz2232bRsAgGgjoATgL4xw5w4AANFBQAEAAI5DQIkwOnQDACB4BJQgEDYAAIgOAkqE0W4FAIDgEVAAAIDjEFAC8FfzQW0IAADRQUABAACOQ0AJwF+DWO9xNa1NoWEtAADBI6AAAADHIaBEGO1WAAAIHgElRFy6AQAgcggoAADAcQgoIaKRLAAAkUNAAQAAjhN0QFm3bp2GDRumtLQ0xcTEaMmSJT7TjTGaNm2a2rRpo6ZNm2rgwIH66quvfOY5dOiQRo0apfj4eCUmJmrs2LE6cuRIrXYEAADUH0EHlKNHj6pHjx6aPXu23+mPP/64nn76ac2ZM0cbNmzQmWeeqcGDB+vEiROeeUaNGqXPP/9cy5cv19KlS7Vu3TqNHz8+9L2IgB07Ko8L5XJNuO/iOX5cGj9eevvt8K4XAABHMbUgySxevNjzuayszKSmpponnnjCM66wsNC4XC6zcOFCY4wx27ZtM5LMxx9/7Jnn3XffNTExMeb777+v0XaLioqMJFNUVFSb4vtlRQprqDguM7P8/bx5/uctKzPm9Ony8bGxtS+HZExiojX+D3+ovE0AAOqCYM7fYW2DsnPnThUUFGjgwIGecQkJCcrIyFBOTo4kKScnR4mJibr00ks98wwcOFCxsbHasGGD3/WWlJSouLjYZ7CDd21IoJqRa6+VOneOXBl2747cugEAcIqwBpSCggJJUkpKis/4lJQUz7SCggIlJyf7TG/cuLGSkpI881SUnZ2thIQEz5Cenh7OYofVO+9I+fnln7mLBwCA4NWJu3iysrJUVFTkGXbbVI1A2AAAIDrCGlBSU1MlSfv27fMZv2/fPs+01NRU7d+/32f6qVOndOjQIc88FblcLsXHx/sMAACg/gprQOnQoYNSU1O1cuVKz7ji4mJt2LBBmZmZkqTMzEwVFhZq06ZNnnlWrVqlsrIyZWRkhLM4jsCzeAAACF7jYBc4cuSI8r0aWezcuVO5ublKSkpSu3btdM899+j3v/+9zjvvPHXo0EEPP/yw0tLSNHz4cEnSBRdcoCFDhmjcuHGaM2eOSktLNXHiRN10001KS0sL244BAIC6K+iAsnHjRvXv39/zecqUKZKk0aNHa968ebr//vt19OhRjR8/XoWFherTp4+WLVumM844w7PM/PnzNXHiRA0YMECxsbEaMWKEnn766TDsjvPQbgUAgOAFHVD69esnU8V1i5iYGM2cOVMzZ84MOE9SUpIWLFgQ7KYBAEADUSfu4gEAAA0LAQUAADgOASXCuIsHAIDgEVCCQINXAACig4AShFBqQwg1AAAEj4ACAAAch4ACAAAch4ASBO/LNTR+BQAgcggoEUaQAQAgeASUENH4FQCAyCGgRBhBBgCA4BFQAACA4xBQQkTbEgAAIoeAEoT16+0uAQAADQMBJQhlZXaXAACAhoGAEqJINn59+eXIrRsAgLqAgOJAN91kdwkAALAXASVENJIFACByCChR9uWX0v79lccbI+XmSkeORL1IAAA4TmO7C9CQ7N4tde5sva9YA/PWW9L110vnnx/9cgEA4DTUoETRJ58EnrZwofX65Zf+p9MjLQCgISGg1BG0eQEANCQElBAVFtpdAgAA6i8CSoiefdbuEgAAUH8RUEJUWhr8MrQjAQCgZggodQThBgDQkBBQQhTtRqs0kgUANCQElDCqLkRQCwIAQM0QUEJE2AAAIHIIKAAAwHEIKGFEOxEAAMIj7AHlnHPOUUxMTKVhwoQJkqR+/fpVmnbnnXeGuxgRRxgBACBywv6wwI8//linT5/2fN66dat+9rOf6b//+78948aNG6eZM2d6Pjdr1izcxXAM2qoAABC8sAeU1q1b+3yeNWuWOnXqpJ/85Ceecc2aNVNqamq4N207f7Uq3uMIKwAA1ExE26CcPHlS//znP3X77bcrxuvsPH/+fLVq1Updu3ZVVlaWjh07VuV6SkpKVFxc7DPYLdxhg1uUAQAoF/YaFG9LlixRYWGhxowZ4xl38803q3379kpLS9OWLVs0depU5eXl6fXXXw+4nuzsbM2YMSOSRXU82rwAABqSiAaUF154QUOHDlVaWppn3Pjx4z3vu3XrpjZt2mjAgAHasWOHOnXq5Hc9WVlZmjJliudzcXGx0tPTI1fwGqjuco4/VdWCUEMCAEC5iAWUb7/9VitWrKiyZkSSMjIyJEn5+fkBA4rL5ZLL5Qp7GWuDGg0AACInYm1Q5s6dq+TkZF1zzTVVzpebmytJatOmTaSKYqua1owQeAAAKBeRGpSysjLNnTtXo0ePVuPG5ZvYsWOHFixYoKuvvlotW7bUli1bNHnyZPXt21fdu3ePRFEixl/wCOWyT222BwBAfRWRgLJixQrt2rVLt99+u8/4uLg4rVixQk899ZSOHj2q9PR0jRgxQr/73e8iUYyICiUw1KYNyo8/Br89AADqqogElEGDBsn4qTpIT0/X2rVrI7HJqLPjksyGDdHfJgAAduBZPCEK9+Wcmiy7a1fo6wcAoC4hoISoppd4wtl2hIa0AICGgoDiEDSCBQCgHAEljHgWDwAA4UFAcYiaXL7hEg8AoKEgoAAAAMchoIRRbWo4uPwDAEA5AkqIahpGwtnVPZd4AAANBQElimpbS0JAAQA0FASUEPEQQAAAIoeAEqJw9yRLGxQAAMoRUGxSMcxQ0wIAQDkCCgAAcBwCSoj8XZLxVwsS6NJNKDUm1LIAABoKAkqIQgkL3mGl4vK0QQEAoBwBJcJqGmSoHQEAoBwBJUQ1vcQjSfv3S2VlNZu3KoQYAEBDQUCJsNOnpZQU6cYbuYwDAEBNEVBCFGxtxmuvBV5+5UrprbdqXyYAAOqLxnYXoK4KZ0dtAweGvk0AAOojalBCxHN1AACIHAJKFPm7zZigAgBAZQSUMCJsAAAQHgQUm4RSgxKOAPThh9Kbb9Z+PQAARBKNZOuQcASUPn2s1507pXPOqf36AACIBGpQQlTbu3jsboOyd6892wUAoCYIKCEqLQ1+GSd11OaksgAAUBEBJUQHDtRuebu7uo/lJw8AcDBOU2Hk9Es83ttq1Ch62wUAIFgElCiy+7LK6dPl76lBAQA4WdhPU9OnT1dMTIzP0KVLF8/0EydOaMKECWrZsqXOOussjRgxQvv27Qt3MaJu7Vpp6NCaz29HDYr3E5UJKAAAJ4vIbcYXXXSRVqxYUb6RxuWbmTx5st5++229+uqrSkhI0MSJE3XDDTfoww8/jERRoqZfP7tLUD3vgGJ3bQ4AAFWJSEBp3LixUlNTK40vKirSCy+8oAULFuinP/2pJGnu3Lm64IILtH79el1++eWRKI4j2dFRG5d4AAB1RUROU1999ZXS0tLUsWNHjRo1Srt27ZIkbdq0SaWlpRro9fjeLl26qF27dsrJyYlEUeDFuwaFRrIAACcLew1KRkaG5s2bp86dO2vv3r2aMWOGrrrqKm3dulUFBQWKi4tTYmKizzIpKSkqKCgIuM6SkhKVlJR4PhcXF4e72FFnRxsUalAAAHVF2APKUK+Wot27d1dGRobat2+vV155RU2bNg1pndnZ2ZoxY0a4imgbf08zDkZtw4wdjWSPH5duvVUaNsx6BQCgJiJ+mkpMTNT555+v/Px8paam6uTJkyosLPSZZ9++fX7brLhlZWWpqKjIM+zevTvCpY4eu+7iiVYj2dmzpddek0aPjs72AAD1Q8QDypEjR7Rjxw61adNGvXr1UpMmTbRy5UrP9Ly8PO3atUuZmZkB1+FyuRQfH+8z1HV2PIPH+xJPtALKwYPR2Q4AoH4J+yWe3/72txo2bJjat2+vPXv26JFHHlGjRo00cuRIJSQkaOzYsZoyZYqSkpIUHx+vSZMmKTMzs0HcweMvFETzLh7vGhQAAJws7AHlu+++08iRI3Xw4EG1bt1affr00fr169W6dWtJ0l/+8hfFxsZqxIgRKikp0eDBg/Xcc8+FuxiOZ0cNindAsespygAA1ETYA8qiRYuqnH7GGWdo9uzZmj17drg3XScFExS+/16aM8f/tE2bpEcflR57TOrcufbbAgDAThHpqA3VCyUsTJsWeNqll1qvn30m7dhR/TbDHVaOH5dCvEkLAIBK6A2jnvn66+hvc8MGqVkzafLk6G8bAFA/EVBsYkdHbZGqQXnwQev1qafCt04AQMNGQImi2nbUBgBAQ0FAsZldNSgAADgZAcUmdocFu7cPAEBVCChR9MADlccRFAAAqIyAEkUbNpS/tyOYRPI2YwAAwomAYrP6EBTqwz4AAJyFgGITu2tQAABwMgKKTezoB8Xf9gEAcCICSgNCKAEA1BUEFJtEqwbl66+llSsDbx8AACfiYYH1XKdO1mtOjtS6tb1lAQCgpqhBsUm026B8/LH/7QMA4EQElAaEUAIAqCsIKDax+y4eAACcjIBik3AEk7Ky0LdZ14NRYaH09tvSqVN2lwQAEAkElDps7ly7S2Cfn/xEuvZaKTvb7pIAACKBgGKTcFziefPN0LZZ2+06wZYt1uv8+faWAwAQGQQUL3X9pG0XjhsAINwIKDahkWx4xMTYXQIAQCQQULxUDAslJfaUI1Lq0yUet/qyHwAAXwQULxVPdvfeG/ltResEy4kcAFCXEFCq8PzzkVt3OALD8uWhb7OuBJa5c6UHH6w75QUAhAfP4vFix0mwNts8frzm89bVthq33269XnutdMUV9pYFABA91KDYxO4wVNdqJG65xe4SAACiiYDiJZon7W3bor/NumznTrtLAACIJgKKTa69VjpxIrrbrI9hqD7uEwCAgOKj4smurCyyJ8DDh+07wTr1xP73v0t/+IPdpQAA2I1Gsl78nbTfeSf65YgEY5wbSryNG2e93nCDdMEF1c9fVxv/AgCqFvYalOzsbF122WVq3ry5kpOTNXz4cOXl5fnM069fP8XExPgMd955Z7iLEhb790d2/dSg+FdcXLP5nL4fAIDQhD2grF27VhMmTND69eu1fPlylZaWatCgQTp69KjPfOPGjdPevXs9w+OPPx7uogStvp/sIrV/9f24AQCiL+yXeJYtW+bzed68eUpOTtamTZvUt29fz/hmzZopNTU13JsPO06+AABEX8QbyRYVFUmSkpKSfMbPnz9frVq1UteuXZWVlaVjx44FXEdJSYmKi4t9hkiIdhg5dix624yJCdwPynvvWd36l5ZKjzwiLVoUnTJF2uuv0wstANRVEW0kW1ZWpnvuuUdXXnmlunbt6hl/8803q3379kpLS9OWLVs0depU5eXl6fXXX/e7nuzsbM2YMSOSRbXFrFnSww9HZ1tVnaSHDLFed++WXn3Ven/TTZEvU6SNGGG9ZmZKw4bZW5a6zhgaJAOIrogGlAkTJmjr1q364IMPfMaPHz/e875bt25q06aNBgwYoB07dqhTp06V1pOVlaUpU6Z4PhcXFys9PT3s5Y32f9pffeWsRrL/+U/0y1FbNTl+e/ZEvhz12cGDUq9eVmidNcvu0gBoKCJ2iWfixIlaunSpVq9erbZt21Y5b0ZGhiQpPz/f73SXy6X4+HifIRL8nex27IjIpmzhhEsdublSQYH/aTTidaann5a+/VZ67DG7SwKgIQl7DYoxRpMmTdLixYu1Zs0adejQodplcnNzJUlt2rQJd3Fq7Y9/jOz6nXTyjHQV/rZtUs+e1vvq9jucZXHSMa6LysrsLgGAhijsNSgTJkzQP//5Ty1YsEDNmzdXQUGBCgoKdPz/Hr27Y8cOPfroo9q0aZO++eYbvfnmm7r11lvVt29fde/ePdzFCUq0T2R2bs+Ok/aHH1Y93e7yhWrTJmnyZKmw0O6SAED9EfYalOeff16S1Rmbt7lz52rMmDGKi4vTihUr9NRTT+no0aNKT0/XiBEj9Lvf/S7cRXG8SHelX9fU1Us8l15qvRYXSy+8ENltAUBDEZFLPFVJT0/X2rVrw73ZsIh2WAhH1fm2bdIll1Q/3913S2+8Uf65un199FFp7lwpJ0dKSSkfP2aM9Nln0vr1UpMmlZdLT5f+/e+adVNfUV0NKG6ffRad7QBAQ8DDAr3YEVBqu8077pBKSmo27wMP1Hy906ZJO3dWboPzj39In3wirV7tf7nvvpNq8tSCQ4ekt96y7mRyi9Txpw0FANQ9PCzQRuE4IZ86VfN5jxwJftuB1l/V8jUpU7t2kvvpB4cOSS1a+K6TRrIA0LARULzY0Wi1ttv0dyKfPVs680zrcoy3H38Mfv2h1j588IG0dKl08qT/6d6PZtq1ywookUJAAYC6h4Bio3CcOGP9XKSbONF6veWW2m8v0DLV1XBcdVXttlXTstZkvmgFFIIQAIQPbVC8HDoU3e2Fow1KVUGh4rq9ay1qut1ott+oWKZwnfAJDgBQ9xBQvPz1r9Hd3saNtb/zI5iA4m3TppqduO0KKBUfbliVvDxp//6arRfB4/gBsAMBxUug9hKRcvq0dN11tVuHv0s8blWdWCZOlObP9x3nL+wECihVBSPvO3Nqwl3O6k6E/kLI7t1Sly6+t0IHWj8AoO4goHipiyeyUGtQJOmXv7Ru9XXbuTPwOtavlx56qGZlOnDA//hAZc3K8i1HxW27bd9eeR7vW6z37JGmTq28H+H4uZaVSTNnSitWBJ4nUt+fkyetp15X1xMvANQnNJKt40KtQXGrrgbHXYOSmek7Ppy3AS9bZg3et0FLlcvfqFHV6xkxwgpSixZZD7cLtJ5QvPyy9Mgj4VtfMJ5+Wvr9762hLoZoAAgFNSh13KpVgaeFo/3ISy9VPf0vf5HC1TFwdY1kqwpjkhVOJOu25arWE4qvvw592XvvtXr7/b/HUQXtiy9C3zYA1FUEFC/17b/TSO9Pfr40ZUr41lexvAcP+n4uKZG2bAl+v2oa1I4erV2j5UDlevJJafNmaeHC4Ne5c6f/tjdFRQQXAPUbAaUei2RA+e476bzzwrvOiuXt29f3c//+Uo8e0uuv1269gVx2mdS9u/Tuu8Gtv6aC6fVXkn74QerY0erwrqL27aULL7SCDwDUR7RB8VLfalByc8OzHnfHb97+85/wrDsQYwLfDTRvXmS26a6RWLBAuugiac4cq4FqhQdza+tWqWvXyJTBX3n8KSqyXt99V+rZM/JlAYBoowbFS30LKBVrIEI1e3blcadPh2fd3ryP/3vvBZ6vcZCxOpSf689+JmVnS3/+szRsmO+0ij301lQ4Gxa71bfvLAC4EVC88Me+5iIdUD79NPB8wTY2rUn/KhVrRL78MvD8VZUt0n7+c/u27URPPCF161a5vRKAuo+AgpBEIqD88EP5e+9u+SuqqnbFn6oCyg8/SHfeKX3+uf9yuPnrgyWStm2TTpyoPP5f//J9JINdofrQIembb3zLsWVL4HY2J09al8bCXd7777fWO2tWeNcLwH4EFIQkEl3gh7vRrVtVJ8XWraXFi6tfxz//GdlyeHvzTasNzKBB/qc/+WTw66wNf9to2VLq0EHau9f6/PjjVgPmX/3K/zqGD7dqOl58MTJljHYv0AAij4DihUs8NReJGpRwmjat/L3Tf65ffGF1Audu+PrCC1XPn51d/j7YfVu2rObPnHrvPempp6qe55NPrNdHH7Ve//GPyvPk5ZXfGfX00zXbNgBwFw9CUlpqdwmq5j5hSoFP4oHGh9qYNdQgdOGF1ut331UfTqTa1V4NHWq9XnKJdNVVVc87ZIj1euWV1a+3qmPWrVvNygYA3qhB8eL0/7Sd5JVXIrv+YNuZVMX75/o//2OdMHftClwLVJN+UL77zuoz5fnny8eVlEh9+ljtIkLh7gk3GNV9ZxcutC4X5eX5jvf33CW35cvLQ5NUuWdeb+5gUlUvv04PswCciYDihYBSP5WVWZcitm+Xxo+3GlXee2/tTpx//KPV6+yvf10+bts264F+Tzxhff7hB+tk75aXV3VbiWPHrNdgvofGWA1Tt23zXa6oyGrEevPN1rTbb/dd7uRJqyGyvy78Bw3y7YOlJjU2kbiFGkDDRkBB1Pz5z/Zs95VXpF69pAsuKB935EjwPbsGq3Vr34auTz4ZuOGr5HtXTE0ZY/XLctFF0t/+Vj4+Pd1qxOpW8UGMJSVWo+ROnarv3r+qgFKTGhQACAV/VhA10b5V163i5Q3JaizqbpQaii1bQltu7VorpLjvfvHXp0swtRF/+IP1pGXJul36ww+t0HL4cOXyvv12+eeysvIyeI/3p6oaHWOkH3+0BtQNr74qzZ9fs3nXrLEaSlO7DDvQSNYLv4QNS0ZG6Mt++GHV06v6Li1fLl13nfTxx1bACGbZiiq2o+nTp3Jtidu11/rfRnWBqGINSsXy3XVX1ctHA7+7NXPypPSLX1jvhwyxbhevSv/+1mvnzuUNrIFooQbFC3/kGpY9eyK37urabWzcKK1YYb16O/NM6a23ardt74a7gdQmoHh/jokpr8Fxy8iouuO0khLrMQwPPWR9PnhQuvRS/7c/jx4tuVxWg+RQa61C9corVt8uFWvgJk2SBg+2wqF7X373u/LpW7ZY5X3zTevzY49Zx6RirZYdvNtdBVOeHTvCXxagWqYOKioqMpJMUVFRWNc7erQx1p9uBobaDSUlNZvvssvsKd+TT5a/f/xx6/t//LgxmzdXvdyaNcbs31/++Z13As/r5j2ue3dj/vd/yz+Xlhpz7bXln3fsKF/u6NHK6zx0yPd31j1+0iTr8/791hCKL7+0ylNx3Zdf7n+bH3xgzEsv+e7v6dOVj4H7/W23GXPqVPl69uwx5scfa1a2H380Zu/e8s/79hnzww+V5/v2W2OOHAm8nuLi8vJ8/XX123XP++yzVc93+rQx27cbU1ZW/TrRsAVz/qYGxYsxdpcA9UVNO7L7+OPIliMQ7++6uwblssuqfzJyv35ScnLlZYNRUlL+fvRoaenS8s+dOkkrV1rv/dVCJSUFXu+pU1bZkpN9t1ETCxZI559ffvnDW3Fx+XvvMhlT+ZEMVd1iPneudNtt1vsff5TS0qQWLWpWvhYtpDZtpMJC626vlBSpVSvf8nz1ldS+vW9j8Iq8G4aH8+/dAw9IXbr49j8E1BYBBYiA3Fy7S1C1igHFGOv262B9/33gabt2VW5js2WL791cCxZUXm7gQKufmUB3WV1yiXV5yDsMfP+9b6PnRYus1xdekM45x2pLcfCg9RDI7Ozydjovvyy99prVVb9kPfYgP993e9u2WcutWuXbs+6CBdLmzeWfi4qqv1Ptf//XaqTqfRt3MEFh9GgriLhNm1a+L+7Gzrt3Wz/Tn//cehCmN+/gHGi7+fnSmDHSgw/6n/7559ZlK+8G3u5b6x95pOryl5VJf/mLlJNT9Xz+zJlj/Qwq2rzZ+vnV9K68TZus8kb6Lj6EQRRqdMIuUpd4br3V/ksDDAzRGP74x/L3f/6zMe++G/5tnHtu6Mt26WLMgQPBLbN7t+/n777z/Tx8uDGNG1vvJ02yLpu4p51/fvn7s86y/h54L9uoUfXbHzmy8riK63EPq1aVvz92rOq/S6dO+S47YoTvZ/flLe/Ldu7h17/2XdfeveXT8vL8b69Zs8rr8b7E4x73yCOVx7n3OZBFi2o2X0Xvvx94Off4P/2pZutyzz97dnBlQHhwiSdExthdAiA6vP87vvfeyNyhUbEmIhjbt/s2PK2Jipdb2rb1/bxkSfl/zc8843t5xfvJ0UeOVL50VZNLdgsXVh4X6JLZT39a/v78863G0t98Y203Jka64gqr8W1MjHXpzdu//uX7ee3awGX66CPrklCfPta62rQpn9a5c/n25syxXs86q7zDQG+7dlkNmb2ftTRjhv8nbvtb/uGHrX2uWLP4/ffW/s2da32eO7e8TG3bSvPmWeNr8l1at676eX75y/L3a9dKl19u1YodPy795CfSzJnS6tXSxRcHV8vzwgvWfvhreP/mm1atn/cT092mTJGuvtqeZ5t99plVruq6GbBVFAJT2EWqBuWWW8L/XyQDA0N0hueft78MtRlatAh92RUrjLnxRv/TnnoqcmX+05+MycnxHXf99cacPGnMN99YtTTr1pVPS0kpf19UZDWadn/+17/8b+PHH425447yz//8pzGbNhnz2mu+NUKxsdZ2P/rImMJCY9autRp9HzpklcW7Fqbi8Ne/+h9/+LAxX31lTEGB1Qj4iy+MWb/emMWLrUbK335rnTvc848ZY30uKzNm40Zj8vN9f74Vuae98UZ54+6yMmubZWXW8qdOWY3uV6ywGo6Xlvo2cPae39vXX1vzfvZZeTndduzwrTWMpmDO31Eumq9nn33WtG/f3rhcLtO7d2+zYcOGGi0XqYDyq185/w8RAwMDg9OHs86yvwzRGnJzy9//139Z5xJ/l9skYz75pPx8U/HSnWTdgeVetnNn63XcOGNcLut9s2bG/OIX1vt33rHW89hj1udHHy1f99tvV163+w65116rPC2agjl/xxhjjB01Ny+//LJuvfVWzZkzRxkZGXrqqaf06quvKi8vT8netwn4UVxcrISEBBUVFSk+Pj5sZfrb36Q77gjb6gJ6//3qnyQLAHC+Vq2s525J1qWp3/zGf58+knVZ8dZbrfelpdJzz/lOHznS/6XCQO6+23dbd99tvfrb/gUXWL1Y+5vmXq6iK67wf2dbbQR1/o54XAqgd+/eZsKECZ7Pp0+fNmlpaSY7O7vaZSNVgzJnjv/Ue/vtlcclJfmf97nnqk/cFft32L7d/v8CQhnatzemU6fglqlNw0nvoXVr+/efgYGBoT4Pd9wR1lOsMSa487ctXd2fPHlSmzZtUlZWlmdcbGysBg4cqBw/LZNKSkpU4tWxQbF3xwRh1LOnlJVlNXjav1965x3raa9jxlhPrb37bulPf5LWr5euucbq8XPRIqth2a5d1q2M48dbSfVvf7Ma2330kdUwr6jIeqDaSy9JzZpZfT+88IJ0/fVWY7Uvv5S6dbMe+nbdddatcN9+azWUGzpUOuMMacAA3/Lm5Ei//a1V63PrrVJCgpXKS0utRobjxlkNoQ4csJ5qu26dlfSvvtrqsyApyXrWxplnlvcGGhtrNX7bsMHqp0GybuNr29Yq38yZVsOq4cOtoWVLq/HhOedIo0ZZ/TR4a9JE+vRT6zkx991nHeOLLrK2efXV0t//bs130UVWb5uvvWb1O9Gnj7X/BQVWQ7b337fmGzTIaqw3aZL1n8aUKeXbOv986cILrWPZsqV1e2jjxtK+fdbPa8sW6xbMitLSrJ9Dhw7Wrahz5pTfsnrmmdK551r7IFnH9H/+x3r/8MPWsZ0zx+p7o7TU/zNprrvOuj3SfTvo9OnW9+qll3zL/uWXlZcNZOBAa3utW1v/ta1bZ+2n2y9+YXVrvnev9bOUpK5dre+Ru/faxo3LG40mJVkPGPz0U6ux3/ffWz/fpk2t78imTb7bT04uv4U1M9M6hp98Iu3caY1r1szavnv9/ftbjQ/9raN5c+vn5X5Y4tCh0rvvVr3//fpZ5apo8GDpvfes9+np/n/ekvXzzs+3Gi66b7MOxhVXWN8Vdy+zrVpZDUa9HzPQq5e1fn8NSStq0iTw07WHDLGeHRUX5/s07ObNrQdFevccnJRkNVI9ccL6XS4rs3733bdzd+4snX229X387/+u/L2p6Mwzrb8V6enW7/mvfmWN//vfrb5YMjOt8ZL13XLv6223WT/P7dvLn/kkST/7mfV9LC62fv/feccaP3y4tZ7kZOu7sG+fdOiQ9fciIcH/z1qy/ib17Ws13j1yxPobNH9++fejfXtrm6tWWb9zffta37nt2619+eQTq0fdiy6y/oZ36mQNS5ZY8wwebN0S3rKl1bdOo0blD9fs1cva3+uvt/5OffCBdWu3ZB33J56Q4uOtn9uBA9bv+A03+Jb/s8+s71F8vNVQ98orre28+qp1TN54wzpOR49afy/GjrW+r6tWSTfeaL0/ccL6uzlihPX7Klnf55dftn7v3Lfa33xz+bSFC63j8u9/W4/ASEjwf3x79w783YgGWy7x7NmzR2effbY++ugjZWZmesbff//9Wrt2rTa4/6L+n+nTp2vGjBmV1hPuSzwAACBygrnEUyduM87KylJRUZFn2B3o3yIAAFAv2HKJp1WrVmrUqJH2Vahb3Ldvn1JTUyvN73K55HK5olU8AABgM1tqUOLi4tSrVy+tdD90Q1JZWZlWrlzpc8kHAAA0TLbUoEjSlClTNHr0aF166aXq3bu3nnrqKR09elS3uZ+mBQAAGizbAsqNN96oAwcOaNq0aSooKNDFF1+sZcuWKSUlxa4iAQAAh7Cto7baiFRHbQAAIHLq3V08AACgYSGgAAAAxyGgAAAAxyGgAAAAxyGgAAAAxyGgAAAAxyGgAAAAx7Gto7bacHfdUlxcbHNJAABATbnP2zXpgq1OBpTDhw9LktLT020uCQAACNbhw4eVkJBQ5Tx1sifZsrIy7dmzR82bN1dMTExY111cXKz09HTt3r2bXmr/D8fEP46LfxyXyjgm/nFc/KvPx8UYo8OHDystLU2xsVW3MqmTNSixsbFq27ZtRLcRHx9f774YtcUx8Y/j4h/HpTKOiX8cF//q63GprubEjUayAADAcQgoAADAcQgoFbhcLj3yyCNyuVx2F8UxOCb+cVz847hUxjHxj+PiH8fFUicbyQIAgPqNGhQAAOA4BBQAAOA4BBQAAOA4BBQAAOA4BBQvs2fP1jnnnKMzzjhDGRkZ+s9//mN3kSJm+vTpiomJ8Rm6dOnimX7ixAlNmDBBLVu21FlnnaURI0Zo3759PuvYtWuXrrnmGjVr1kzJycm67777dOrUqWjvSq2sW7dOw4YNU1pammJiYrRkyRKf6cYYTZs2TW3atFHTpk01cOBAffXVVz7zHDp0SKNGjVJ8fLwSExM1duxYHTlyxGeeLVu26KqrrtIZZ5yh9PR0Pf7445HetVqp7riMGTOm0vdnyJAhPvPUt+OSnZ2tyy67TM2bN1dycrKGDx+uvLw8n3nC9XuzZs0aXXLJJXK5XDr33HM1b968SO9eSGpyTPr161fpu3LnnXf6zFOfjokkPf/88+revbuno7XMzEy9++67nukN7XsSMgNjjDGLFi0ycXFx5sUXXzSff/65GTdunElMTDT79u2zu2gR8cgjj5iLLrrI7N271zMcOHDAM/3OO+806enpZuXKlWbjxo3m8ssvN1dccYVn+qlTp0zXrl3NwIEDzebNm80777xjWrVqZbKysuzYnZC988475qGHHjKvv/66kWQWL17sM33WrFkmISHBLFmyxHz66afmuuuuMx06dDDHjx/3zDNkyBDTo0cPs379evP++++bc88914wcOdIzvaioyKSkpJhRo0aZrVu3moULF5qmTZua//f//l+0djNo1R2X0aNHmyFDhvh8fw4dOuQzT307LoMHDzZz5841W7duNbm5uebqq6827dq1M0eOHPHME47fm6+//to0a9bMTJkyxWzbts0888wzplGjRmbZsmVR3d+aqMkx+clPfmLGjRvn810pKiryTK9vx8QYY958803z9ttvmy+//NLk5eWZBx980DRp0sRs3brVGNPwviehIqD8n969e5sJEyZ4Pp8+fdqkpaWZ7OxsG0sVOY888ojp0aOH32mFhYWmSZMm5tVXX/WM++KLL4wkk5OTY4yxTmCxsbGmoKDAM8/zzz9v4uPjTUlJSUTLHikVT8RlZWUmNTXVPPHEE55xhYWFxuVymYULFxpjjNm2bZuRZD7++GPPPO+++66JiYkx33//vTHGmOeee860aNHC57hMnTrVdO7cOcJ7FB6BAsr1118fcJmGcFz2799vJJm1a9caY8L3e3P//febiy66yGdbN954oxk8eHCkd6nWKh4TY6yAcvfddwdcpr4fE7cWLVqYv//973xPgsAlHkknT57Upk2bNHDgQM+42NhYDRw4UDk5OTaWLLK++uorpaWlqWPHjho1apR27dolSdq0aZNKS0t9jkeXLl3Url07z/HIyclRt27dlJKS4pln8ODBKi4u1ueffx7dHYmQnTt3qqCgwOc4JCQkKCMjw+c4JCYm6tJLL/XMM3DgQMXGxmrDhg2eefr27au4uDjPPIMHD1ZeXp5+/PHHKO1N+K1Zs0bJycnq3Lmz7rrrLh08eNAzrSEcl6KiIklSUlKSpPD93uTk5Piswz1PXfhbVPGYuM2fP1+tWrVS165dlZWVpWPHjnmm1fdjcvr0aS1atEhHjx5VZmYm35Mg1MmHBYbbDz/8oNOnT/t8GSQpJSVF27dvt6lUkZWRkaF58+apc+fO2rt3r2bMmKGrrrpKW7duVUFBgeLi4pSYmOizTEpKigoKCiRJBQUFfo+Xe1p94N4Pf/vpfRySk5N9pjdu3FhJSUk+83To0KHSOtzTWrRoEZHyR9KQIUN0ww03qEOHDtqxY4cefPBBDR06VDk5OWrUqFG9Py5lZWW65557dOWVV6pr166SFLbfm0DzFBcX6/jx42ratGkkdqnW/B0TSbr55pvVvn17paWlacuWLZo6dary8vL0+uuvS6q/x+Szzz5TZmamTpw4obPOOkuLFy/WhRdeqNzc3Ab9PQkGAaWBGjp0qOd99+7dlZGRofbt2+uVV16pF19sRNZNN93ked+tWzd1795dnTp10po1azRgwAAbSxYdEyZM0NatW/XBBx/YXRTHCHRMxo8f73nfrVs3tWnTRgMGDNCOHTvUqVOnaBczajp37qzc3FwVFRXptdde0+jRo7V27Vq7i1WncIlHUqtWrdSoUaNKraj37dun1NRUm0oVXYmJiTr//POVn5+v1NRUnTx5UoWFhT7zeB+P1NRUv8fLPa0+cO9HVd+L1NRU7d+/32f6qVOndOjQoQZ1rDp27KhWrVopPz9fUv0+LhMnTtTSpUu1evVqtW3b1jM+XL83geaJj4937D8PgY6JPxkZGZLk812pj8ckLi5O5557rnr16qXs7Gz16NFDf/3rXxv09yRYBBRZX6RevXpp5cqVnnFlZWVauXKlMjMzbSxZ9Bw5ckQ7duxQmzZt1KtXLzVp0sTneOTl5WnXrl2e45GZmanPPvvM5yS0fPlyxcfH68ILL4x6+SOhQ4cOSk1N9TkOxcXF2rBhg89xKCws1KZNmzzzrFq1SmVlZZ4/xJmZmVq3bp1KS0s98yxfvlydO3d29GWMYHz33Xc6ePCg2rRpI6l+HhdjjCZOnKjFixdr1apVlS5Phev3JjMz02cd7nmc+LeoumPiT25uriT5fFfq0zEJpKysTCUlJQ3yexIyu1vpOsWiRYuMy+Uy8+bNM9u2bTPjx483iYmJPq2o65N7773XrFmzxuzcudN8+OGHZuDAgaZVq1Zm//79xhjrNrh27dqZVatWmY0bN5rMzEyTmZnpWd59G9ygQYNMbm6uWbZsmWndunWdu8348OHDZvPmzWbz5s1GknnyySfN5s2bzbfffmuMsW4zTkxMNG+88YbZsmWLuf766/3eZtyzZ0+zYcMG88EHH5jzzjvP53bawsJCk5KSYn75y1+arVu3mkWLFplmzZo59nZaY6o+LocPHza//e1vTU5Ojtm5c6dZsWKFueSSS8x5551nTpw44VlHfTsud911l0lISDBr1qzxuWX22LFjnnnC8Xvjvn30vvvuM1988YWZPXu2Y28fre6Y5Ofnm5kzZ5qNGzeanTt3mjfeeMN07NjR9O3b17OO+nZMjDHmgQceMGvXrjU7d+40W7ZsMQ888ICJiYkx//73v40xDe97EioCipdnnnnGtGvXzsTFxZnevXub9evX212kiLnxxhtNmzZtTFxcnDn77LPNjTfeaPLz8z3Tjx8/bn7961+bFi1amGbNmpn/+q//Mnv37vVZxzfffGOGDh1qmjZtalq1amXuvfdeU1paGu1dqZXVq1cbSZWG0aNHG2OsW40ffvhhk5KSYlwulxkwYIDJy8vzWcfBgwfNyJEjzVlnnWXi4+PNbbfdZg4fPuwzz6effmr69OljXC6XOfvss82sWbOitYshqeq4HDt2zAwaNMi0bt3aNGnSxLRv396MGzeuUpivb8fF3/GQZObOneuZJ1y/N6tXrzYXX3yxiYuLMx07dvTZhpNUd0x27dpl+vbta5KSkozL5TLnnnuuue+++3z6QTGmfh0TY4y5/fbbTfv27U1cXJxp3bq1GTBggCecGNPwviehijHGmOjV1wAAAFSPNigAAMBxCCgAAMBxCCgAAMBxCCgAAMBxCCgAAMBxCCgAAMBxCCgAAMBxCCgAAMBxCCgAAMBxCCgAAMBxCCgAAMBxCCgAAMBx/j8/U4gMUKrDmwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Se importa el módulo Counter\n",
    "from collections import Counter\n",
    "\n",
    "#Se importa el módulo plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Se asigna un objeto de clase Counter\n",
    "midiccionario = Counter()\n",
    "\n",
    "#Se crea el diccionario con las palabras del conjunto de entrenamiento\n",
    "for k in range(len(x_train)):\n",
    "  midiccionario.update(x_train[k])\n",
    "\n",
    "\n",
    "print('Longitud del diccionario:', len(midiccionario))\n",
    "print('\\n(word,frequency):')\n",
    "print(midiccionario.most_common(10))\n",
    "\n",
    "# Veamos la gráfica de palabras nuestro diccionario con base a la frecuencia de las palabras/tokens:\n",
    "plt.plot(list(np.arange(len(midiccionario))), list(midiccionario.values()), color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNcZad_yyIvk"
   },
   "source": [
    "**Filtrado por frecuencia de aparición hasta llegar al tamaño de vocabulario deseado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "SBDoD_d0x8yz",
    "outputId": "ca487d7f-920b-4e0e-deb4-8d3ca6ce3843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nueva longitud del nuevo vocabulario: 1420\n",
      "[('star', 18), ('fare', 2), ('much', 39), ('good', 202), ('people', 23)]\n"
     ]
    }
   ],
   "source": [
    "#Frecuencia mínima deseada\n",
    "min_freq = 2\n",
    "\n",
    "#Copia de midiccionario para realizar operaciones\n",
    "midicc = {}\n",
    "\n",
    "#Ciclo para filtar los elementos con base a su frecuencia\n",
    "for token, freq in midiccionario.items():\n",
    "    if freq >= min_freq:\n",
    "        midicc[token] = freq\n",
    "print('Nueva longitud del nuevo vocabulario:', len(midicc))\n",
    "print(list(midicc.items())[0:5])     # veamos algunos elementos del diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "oCg0nFcxG-pM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "co star fare much good people like morgan freeman jonah hill ed helm waste\n",
      "tonight elk filet special suck\n",
      "pay bill tip felt server terrible job\n"
     ]
    }
   ],
   "source": [
    "x_train_docs = []\n",
    "for t in range(len(x_train)):\n",
    "  x_train_docs.append(' '.join(x_train[t]))\n",
    "\n",
    "x_val_docs = []\n",
    "for v in range(len(x_val)):\n",
    "  x_val_docs.append(' '.join(x_val[v]))\n",
    "\n",
    "x_test_docs = []\n",
    "for e in range(len(x_test)):\n",
    "  x_test_docs.append(' '.join(x_test[e]))\n",
    "\n",
    "\n",
    "\n",
    "# Verifica que los primeros comentarios de Train están cada uno como un solo string:\n",
    "for x in range(3):\n",
    "  print(x_train_docs[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "nRoQLNtZNL0y",
    "outputId": "fc527de1-9f6e-4fcf-b366-feb8093dd138"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes: ['co', 'star', 'fare', 'much', 'good', 'people', 'like', 'morgan', 'freeman', 'jonah', 'hill', 'ed', 'helm', 'waste']\n",
      "Antes x_train: ['battery', 'completely', 'useless']\n",
      "Antes y_train: ['accent', 'absolutely', 'abysmal']\n",
      "Después: co star fare much good people like morgan freeman jonah hill ed helm waste\n",
      "Después: battery completely useless\n",
      "Después: accent absolutely abysmal\n",
      "Antes: ['tonight', 'elk', 'filet', 'special', 'suck']\n",
      "Antes x_train: ['service', 'super', 'friendly']\n",
      "Antes y_train: ['plot', 'keep', 'go', 'first', 'place']\n",
      "Después: tonight elk filet special suck\n",
      "Después: service super friendly\n",
      "Después: plot keep go first place\n",
      "Antes: ['pay', 'bill', 'tip', 'felt', 'server', 'terrible', 'job']\n",
      "Antes x_train: ['try', 'make', 'call', 'exercise', 'frustration']\n",
      "Antes y_train: ['ship', 'time', 'also', 'quick']\n",
      "Después: pay bill tip felt server terrible job\n",
      "Después: try make call exercise frustration\n",
      "Después: ship time also quick\n"
     ]
    }
   ],
   "source": [
    "# Podemos ver algunos de los comentarios de entrenamiento, antes y después\n",
    "# de incluir la condición de la frecuencia mínima de ocurrencia de un token:\n",
    "\n",
    "for k in range(3):\n",
    "  print('Antes:', x_train[k])\n",
    "  print('Antes x_train:', x_val[k])\n",
    "  print('Antes y_train:', x_test[k])\n",
    "  print('Después:', x_train_docs[k])\n",
    "  print('Después:', x_val_docs[k])\n",
    "  print('Después:', x_test_docs[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_ySQygSEdcK"
   },
   "source": [
    "# **Pregunta 5**\n",
    "Utilizarás los vectores embebidos FastText preentrenados por Facebook.\n",
    "\n",
    "Incluye una tabla comparativa de pros y contras entre los modelos FastText, word2vec de Google y Glove de Stanford. Puedes consultar sus páginas correspondientes:\n",
    "- https://fasttext.cc/\n",
    "- https://code.google.com/archive/p/word2vec/\n",
    "- https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DD8-dBWo9T9j"
   },
   "source": [
    "| Características | FastText | Word2Vec | GloVe |\n",
    "| ----------- | ----------- | ----------- | ----------- |\n",
    "| **Institución desarrolladora** | Facebook AI | Google | Stanford University |\n",
    "| **Modelo** | Basado en la arquitectura de skip-gram y CBOW | Basado en las arquitecturas de skip-gram y CBOW | Basado en la matriz de co-ocurrencia de palabras en el corpus |\n",
    "| **Manejo de palabras fuera del vocabulario (OOV)** | Buen manejo gracias al uso de n-grams subwords | No lo soporta | No lo soporta |\n",
    "| **Manejo de palabras raras** | Buen manejo gracias al uso de n-grams subwords | Puede tener dificultades con palabras raras | Buen manejo dependiendo de la frecuencia en la matriz de co-ocurrencia |\n",
    "| **Velocidad de entrenamiento** | Media | Rápido | Lento en comparación con FastText y Word2Vec debido al uso de la matriz de co-ocurrencia |\n",
    "| **Dimensiones de los vectores** | Configurable, hasta 300 dimensiones | Configurable, hasta 300 dimensiones | Configurable, hasta 300 dimensiones |\n",
    "| **Requisitos de memoria** | Moderados, debido a los subwords n-grams | Bajos, sólo necesita palabras y contextos | Altos, debido a la matriz de co-ocurrencia |\n",
    "| **Interpretación semántica** | Buena, similar a Word2Vec | Buena, basada en contextos cercanos | Buena, basada en relaciones semánticas y sintácticas |\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Es importante mencionar que cada uno de estos modelos puede ser el más adecuado dependiendo de las necesidades específicas del problema que se esté abordando.\n",
    "\n",
    "Por ejemplo, si necesitas manejar palabras fuera del vocabulario o palabras raras, FastText podría ser la mejor opción; si la memoria es una limitación, Word2Vec podría ser más adecuado; GloVe, por otro lado, podría ser más útil para capturar relaciones semánticas y sintácticas entre palabras.\n",
    "\n",
    "Por otro lado, GloVe podría desempeñarse mejor que Word2Vec para tareas de analogía de palabras, y también muestra un desempeño superior en tareas de similitud y de reconocimiento de nombre de entidades. Mientras que FastText logra un mejor desempeño en tareas sintácticas. Por último, Word2Vec sobrepasa a FastText en tareas semánticas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Bf1J3AiEt-d"
   },
   "source": [
    "# **Pregunta 6**\n",
    "Utiliza el modelo **FastText** de vectores embebidos pre-entrenados de dimensión 300 para generar un nuevo diccionario clave-valor, donde la “clave” será cada token o palabra de tu vocabulario y el “valor” será su vector embebido de dimensión 300. Este diccionario deberá ser del mismo tamaño que el vocabulario previo que hayas construido previamente.\n",
    "https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "\n",
    "**NOTA**: Debido a la cantidad de recursos computacionales que demanda cargar los vectores FastText (son 2 millones de vectores), es recomendable que una vez que generes el nuevo vocabulario de vectores embebidos, guardes dicho diccionario en un archivo (pickle, npz o el que consideres más adecuado). Una vez realizado lo anterior, puedes borrar la variable de FastText para liberar memoria RAM. De esta manera, ya tienes tu vocabulario de vectores embebidos de acuerdo a los tokens que consideras más adecuados para tu problema y puedes usarlo rápidamente\n",
    "cuando lo necesites. En dado caso apóyense entre los miembros del equipo de tener dificultades para generar el vocabulario y por mientras puedes usar el archivo del vocabulario que alguno haya generado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9H3SjaXtFjbJ"
   },
   "source": [
    "**Se instala el módulo de Cython y FastText**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "W8ZJ0jF1EcUq",
    "outputId": "b4cbd8d5-442c-47f8-e892-81230480001b"
   },
   "outputs": [],
   "source": [
    "# !pip install fasttext\n",
    "# !pip install Cython --install-option=\"--no-cython-compile\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QeNah30Fz6T"
   },
   "source": [
    "**Se importa el módulo de fasttext**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "WcwHjBoFF6sl",
    "outputId": "b031ab24-e668-45b9-caf3-e050fa51f3c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cc.en.300.bin'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "\n",
    "#Se descargan los el modelo de idioma inglés\n",
    "fasttext.util.download_model('en', if_exists='ignore')  # English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "KWrcylNjJVw4",
    "outputId": "fcfa4952-a72f-4860-8c69-c3250c8949ba"
   },
   "outputs": [],
   "source": [
    "#Se utiliza el modelo FastText de vectores embebidos pre-entrenados de dimensión 300\n",
    "ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Cizy_S4-LDa0",
    "outputId": "6a43a925-62ad-4f33-c6cd-feb164dc738b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del vocabulario de vectores embebidos: 1420\n",
      "Las dimensiones de midicc_vec son: 1420,300\n",
      "[('star', array([-2.86828041e-01,  1.15123533e-01,  5.38213179e-02,  6.26803637e-02,\n",
      "        2.47128960e-02, -2.57342309e-02,  1.47269234e-01, -1.16852485e-01,\n",
      "        1.43789779e-02,  2.02018499e-01, -6.00243136e-02, -6.75183982e-02,\n",
      "       -4.77372715e-03,  4.89413664e-02,  1.16688116e-02, -3.23957461e-03,\n",
      "       -1.23359617e-02, -8.51226449e-02, -4.92033921e-02,  6.35383427e-02,\n",
      "        8.86741839e-03,  1.40952796e-01,  1.09847665e-01,  1.25429276e-02,\n",
      "       -4.25020084e-02, -8.08417723e-02,  2.70867231e-03,  3.24510969e-02,\n",
      "        1.41084492e-02,  1.06206566e-01,  1.08138800e-01, -5.41383438e-02,\n",
      "        5.69636673e-02,  5.37327491e-02, -7.06092343e-02, -9.78406295e-02,\n",
      "       -1.20484188e-01, -4.16465327e-02, -8.21356028e-02,  4.71536033e-02,\n",
      "        9.90687776e-03,  4.89758067e-02, -1.33870468e-01, -1.54928997e-01,\n",
      "       -1.81018680e-01,  1.78726465e-02,  7.79893203e-03, -8.59202892e-02,\n",
      "       -2.29937509e-02, -1.81513757e-01, -1.04256801e-01,  1.19395129e-01,\n",
      "        7.99314678e-03,  5.44246733e-02,  1.18487053e-01,  4.88866717e-02,\n",
      "        5.15220016e-02, -4.63055186e-02,  8.03847145e-03, -5.37553839e-02,\n",
      "       -1.83139741e-02, -9.42408741e-02, -1.01035193e-01,  3.56963836e-02,\n",
      "        1.93327591e-02,  2.09810555e-01,  2.19372492e-02,  2.13999581e-02,\n",
      "        1.16238985e-02, -1.17042363e-01, -1.48543967e-02,  3.18749472e-02,\n",
      "       -1.81292221e-01, -8.17631930e-02,  2.79697850e-02, -3.79535183e-02,\n",
      "        1.45776663e-02,  1.37915611e-01, -8.08674842e-02,  2.51751058e-02,\n",
      "       -6.64169192e-02,  9.05220862e-03,  1.35277987e-01,  2.18077898e-02,\n",
      "        3.70039642e-02, -1.99556798e-02, -1.50145322e-01, -8.03397596e-03,\n",
      "       -7.00799674e-02, -2.94313934e-02, -3.02728191e-02,  1.93609685e-01,\n",
      "        1.89876668e-02, -7.70288929e-02,  1.80713087e-02,  1.10033236e-01,\n",
      "        7.12299794e-02, -4.59963679e-02, -1.72077119e-01,  3.16679366e-02,\n",
      "       -5.98362945e-02, -8.74337852e-02, -8.86409208e-02, -2.87565850e-02,\n",
      "       -5.81971705e-02,  1.01937577e-01,  3.15561742e-02,  1.15741333e-02,\n",
      "       -1.06359929e-01,  1.87610969e-01,  1.45370346e-02,  5.99830151e-02,\n",
      "        9.92235392e-02,  1.91061702e-02, -2.38206740e-02, -2.17346236e-01,\n",
      "        7.70934811e-03, -3.35183665e-02, -1.03727773e-01, -4.16280292e-02,\n",
      "        1.53034225e-01,  8.58682245e-02,  3.14186066e-02,  1.54228285e-01,\n",
      "       -8.03690311e-03,  3.32052186e-02,  4.11878666e-03,  1.05484031e-01,\n",
      "        7.57255778e-02, -3.18720341e-02,  1.70250125e-02,  6.56677261e-02,\n",
      "        1.23368874e-01, -3.03245634e-02,  2.33012419e-02, -1.44071028e-01,\n",
      "        1.45928591e-01,  6.17721789e-02,  1.98618054e-01, -1.88623518e-01,\n",
      "       -6.05288260e-02,  7.98067078e-02,  3.88783626e-02, -1.24917820e-01,\n",
      "       -1.37684941e-01,  6.50793165e-02, -2.99405992e-01, -3.73671472e-04,\n",
      "        4.60229479e-02, -7.02350959e-02, -3.00859064e-02, -1.02555119e-01,\n",
      "       -8.37509986e-03, -3.45986453e-04,  9.31164846e-02, -3.90904620e-02,\n",
      "        1.14622459e-01,  1.26173794e-01,  5.39926952e-03,  2.46864315e-02,\n",
      "       -7.46607184e-02,  6.94717746e-03,  1.56693712e-01, -1.52236253e-01,\n",
      "        3.30955088e-02, -4.14339192e-02, -6.96366578e-02,  9.96302366e-02,\n",
      "       -6.03845380e-02,  9.29320753e-02, -2.12934427e-03, -6.01781867e-02,\n",
      "       -7.10362718e-02, -1.18315414e-01, -6.35388717e-02,  6.41066134e-02,\n",
      "       -5.91891073e-02,  1.27110809e-01,  7.15065151e-02,  6.29523173e-02,\n",
      "       -5.46345413e-02,  2.89074313e-02, -1.59469962e-01, -7.92971104e-02,\n",
      "       -1.03111260e-01, -8.40404853e-02,  6.54209182e-02,  6.68521225e-02,\n",
      "       -2.92568877e-02,  2.20480785e-01,  9.37886834e-02, -9.02144909e-02,\n",
      "       -4.41652164e-02,  8.60180557e-02, -1.45871434e-02,  4.97262180e-02,\n",
      "       -1.41114324e-01,  8.82492661e-02,  9.48378909e-03, -9.70369801e-02,\n",
      "        1.59810316e-02,  1.26596987e-02,  3.80288512e-02,  3.90619189e-02,\n",
      "        9.13637877e-02, -8.60894620e-02,  1.01811588e-01,  6.69082999e-02,\n",
      "        1.05031997e-01,  1.48328632e-01,  6.92542717e-02, -1.06625669e-01,\n",
      "       -1.52740449e-01, -7.56940758e-03,  3.13936025e-02,  3.49867865e-02,\n",
      "       -2.09618788e-02, -1.42902760e-02,  6.80341348e-02,  6.19825125e-02,\n",
      "       -2.84822695e-02,  1.18321627e-01, -1.13135815e-01, -1.77281257e-02,\n",
      "       -5.60616702e-03,  8.14713836e-02, -1.53869148e-02,  8.16864222e-02,\n",
      "       -1.04721271e-01,  1.58673406e-01, -7.53961354e-02,  3.07477619e-02,\n",
      "        9.25838854e-03, -1.48327835e-02,  7.91117456e-03, -3.18586826e-04,\n",
      "       -8.03159773e-02,  6.46696135e-04, -7.53018484e-02, -1.21981822e-01,\n",
      "        4.21633124e-02, -6.28293380e-02, -9.21363831e-02, -5.31597510e-02,\n",
      "        8.62716362e-02, -6.90141022e-02,  2.69403346e-02,  1.61921620e-01,\n",
      "       -4.50303815e-02,  2.98184454e-02, -3.96693758e-05, -7.90106505e-02,\n",
      "       -3.03728543e-02,  1.16063416e-01,  2.34403973e-03,  9.55789983e-02,\n",
      "       -2.87741404e-02, -9.72413719e-02,  3.45763527e-02,  1.02634273e-01,\n",
      "       -2.12719902e-01,  4.99785393e-02, -5.83627820e-02,  1.52304163e-02,\n",
      "       -1.22847423e-01,  4.66357172e-02,  1.46242663e-01,  1.13413274e-01,\n",
      "        1.09998845e-01, -2.39889026e-02,  3.31177339e-02,  4.13419865e-02,\n",
      "       -1.06826507e-01,  4.97730151e-02,  6.61367327e-02, -7.30071217e-02,\n",
      "       -2.99715679e-02,  6.65043890e-02, -5.69159463e-02,  4.16496157e-04,\n",
      "        1.42523021e-01, -4.14542109e-02, -1.05582647e-01, -1.55546203e-01,\n",
      "        6.32830709e-02,  1.06834993e-01, -9.86435339e-02,  7.51124090e-03,\n",
      "       -8.39522183e-02, -1.09830283e-01, -2.86104158e-02,  1.05289333e-01,\n",
      "       -1.09692931e-01,  1.05054498e-01,  1.07300431e-02,  1.82751417e-02,\n",
      "       -4.68385331e-02,  5.67049533e-02, -5.08587807e-03, -1.43625721e-01],\n",
      "      dtype=float32))]\n"
     ]
    }
   ],
   "source": [
    "#Copia de midicc para realizar operaciones\n",
    "midicc_vec = {}\n",
    "\n",
    "#asignar el vector resultante a cada elemento del diccionario\n",
    "for word in midicc:\n",
    "    vec_word = ft.get_word_vector(word)\n",
    "    midicc_vec[word] = vec_word\n",
    "\n",
    "print('Longitud del vocabulario de vectores embebidos:', len(midicc_vec))\n",
    "print('Las dimensiones de midicc_vec son: {},{}'.format(len(midicc_vec), len(list(midicc_vec.items())[0][1])))   # veamos algunos elementos del diccionario.\n",
    "print(list(midicc_vec.items())[0:1])     # veamos algunos elementos del diccionario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpRFOjOvwArc"
   },
   "source": [
    "# **Pregunta 7**\n",
    "Una manera de utilizar los vectores embebidos con modelos de aprendizaje automático en\n",
    "documentos de texto, es asignar a cada comentario filtrado el vector embebido de dimensión 300\n",
    "que resulta de promediar todos sus tokens. Así, en este ejercicio deberás generar los arreglos\n",
    "correspondientes para los conjuntos de entrenamiento, validación y prueba. Los llamaremos\n",
    "trainEmb, valEmb y testEmb, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "cLtl3z8SfU6O"
   },
   "outputs": [],
   "source": [
    "#función para transformar un conjunto de documentos a sus vectores embebidos en un diccionario\n",
    "def documento_a_documento_de_vectores_embebidos(docs, vect_dic):\n",
    "\n",
    "#Se inicializan lista vacía para el promedio de los vectores\n",
    "    emb_vect_doc = []\n",
    "\n",
    "    #Ciclo para extraer cada documento del conjunto\n",
    "    for doc in docs:\n",
    "\n",
    "        #Lista vacía temporal para juntar los vectores del diccionario\n",
    "        tmp_doc = []\n",
    "\n",
    "        #Ciclo para extraer todos los tokens del documento\n",
    "        for token in doc:\n",
    "            if token not in vect_dic:\n",
    "                continue\n",
    "            #Se obtiene y añade a la lista el vector correspondiente\n",
    "            tmp_doc.append(vect_dic[token])\n",
    "\n",
    "        #Se añade a la lista de vectores\n",
    "        emb_vect_doc.append(tmp_doc)\n",
    "\n",
    "    return emb_vect_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "rSqw7RpbmSOt",
    "outputId": "0b81a4a6-7d4a-4b47-c49b-d7c7c55cbf88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de elementos train_x_vect es: 2100\n",
      "\n",
      "La cantidad de elementos val_x_vect es: 450\n",
      "\n",
      "La cantidad de elementos test_x_vect es: 450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Se transforman todos los tokens de cada documento a su vector correspondiente en el diccionario\n",
    "x_train_vect = documento_a_documento_de_vectores_embebidos(x_train, midicc_vec)\n",
    "x_val_vect = documento_a_documento_de_vectores_embebidos(x_val, midicc_vec)\n",
    "x_test_vect = documento_a_documento_de_vectores_embebidos(x_test, midicc_vec)\n",
    "\n",
    "print('La cantidad de elementos train_x_vect es: {}\\n'.format(len(x_train_vect)))\n",
    "print('La cantidad de elementos val_x_vect es: {}\\n'.format(len(x_val_vect)))\n",
    "print('La cantidad de elementos test_x_vect es: {}\\n'.format(len(x_test_vect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ynopEhb0eMIg"
   },
   "outputs": [],
   "source": [
    "#Funcion para calcular el promedio de vectores en un documento\n",
    "def promedio_de_lista_de_vectores(vec_docs):\n",
    "\n",
    "    #Lista vacía\n",
    "    vectores_promedio = []\n",
    "\n",
    "    #Ciclo para extraer el documento de vectores\n",
    "    for vectores in vec_docs:\n",
    "        vector_promedio = np.mean(vectores, axis=0)\n",
    "        #Se añade a la lista de vectores promedio\n",
    "        if vector_promedio.shape == ():\n",
    "            vectores_promedio.append(np.zeros((300,)))\n",
    "            continue\n",
    "        vectores_promedio.append(vector_promedio)\n",
    "    vect_promedio_ar = np.array(vectores_promedio, dtype=float)\n",
    "        \n",
    "\n",
    "    return vect_promedio_ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebsJniyVwOnr"
   },
   "source": [
    "**¿Cuáles son sus dimensiones?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "9trzJgjjjIGl",
    "outputId": "1449a6ad-5731-407c-9f56-2cf92fe5c20a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las dimensiones de trainEmb son: (2100, 300)\n",
      "\n",
      "Las dimensiones de valEmb son: (450, 300)\n",
      "\n",
      "Las dimensiones de testEmb son: (450, 300)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alberto Patraca\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\Alberto Patraca\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "#Se calculan los vectores promedio de cada conjunto de documentos\n",
    "trainEmb = promedio_de_lista_de_vectores(x_train_vect)\n",
    "valEmb = promedio_de_lista_de_vectores(x_val_vect)\n",
    "testEmb = promedio_de_lista_de_vectores(x_test_vect)\n",
    "\n",
    "print('Las dimensiones de trainEmb son: {}\\n'.format(trainEmb.shape))\n",
    "print('Las dimensiones de valEmb son: {}\\n'.format(valEmb.shape))\n",
    "print('Las dimensiones de testEmb son: {}\\n'.format(testEmb.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6iWFHhXxwTJQ"
   },
   "source": [
    "**¿Se podrían usar para su representación matrices dispersas (sparse matrices) como en el caso de la matriz Tf-idf?**\n",
    "\n",
    "Si, se podrían usar matrices dispersas (sparse matrices) para representar los vectores embebidos en documentos de texto, al igual que en el caso de la matriz Tf-idf. Pero este no operaría de manera eficiente, sus resultados serían más generalizados.\n",
    "\n",
    "Para nuestro caso, al obtener el promedio de todos los vectores presentes en cada documento, se obtuvieron vectores de 300 elementos cada uno con valores distintos a cero. En este caso se tiene una matriz densa, no una dispersa como las que se tratan en Ti-idf.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-unf1wrx3aA"
   },
   "source": [
    "# **Pregunta 8**\n",
    "Utiliza los modelos de regresión lineal y bosque aleatorio (random forest) y encuentra sus\n",
    "desempeños (accuracy). Compara los resultados con los de la semana anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "_ByrS1Kvytfg"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jco9mqiqhHRd"
   },
   "source": [
    "Definición del modelo y rango inicial de hiperparámetros:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "AdB-BfdjhA0H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100\n",
      "2100\n"
     ]
    }
   ],
   "source": [
    "# Definir rango inicial de hiperparámetros\n",
    "max_depth_range = [5, 10, 15, 20, None]\n",
    "min_samples_leaf_range = [1, 2, 4, 8]\n",
    "min_samples_split_range = [2, 5, 10, 20]\n",
    "\n",
    "# Crear modelo inicial\n",
    "rf_model = RandomForestClassifier()\n",
    "print(len(trainEmb))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PazpfYN4hJBW"
   },
   "source": [
    "Evaluación manual de diferentes combinaciones de hiperparámetros:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "BfNVosWehD0T",
    "outputId": "0e9e90d5-28aa-4d51-9cfb-f8912e9d985d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 80 candidates, totalling 480 fits\n",
      "Mejor valor de exactitud obtenido con la mejor combinación: 0.77\n",
      "Mejor combinación de valores encontrados de los hiperparámetros: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kfold= RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=7)\n",
    "\n",
    "rf_params= {'max_depth': max_depth_range, \n",
    "            'min_samples_leaf': min_samples_leaf_range,\n",
    "            'min_samples_split': min_samples_split_range}\n",
    "\n",
    "rf_grid= GridSearchCV(rf_model, rf_params, scoring='accuracy', cv=kfold, n_jobs=-1, verbose=3, error_score='raise')\n",
    "rf_grid.fit(trainEmb, y_train)\n",
    "rf_best = rf_grid.best_params_\n",
    "\n",
    "print(f'Mejor valor de exactitud obtenido con la mejor combinación: {round(rf_grid.best_score_,2)}')\n",
    "print(f'Mejor combinación de valores encontrados de los hiperparámetros: {rf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "4ZfVQ2yihU-8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud en el conjunto de entrenamiento: 0.989\n",
      "Exactitud en el conjunto de validación: 0.756\n"
     ]
    }
   ],
   "source": [
    "rf_best = rf_grid.best_params_\n",
    "final_rf_model = RandomForestClassifier(max_depth=rf_best['max_depth'], \n",
    "                                        min_samples_leaf=rf_best['min_samples_leaf'],\n",
    "                                        min_samples_split=rf_best['min_samples_split'])\n",
    "final_rf_model.fit(trainEmb, y_train)\n",
    "train_accuracy = final_rf_model.score(trainEmb, y_train)\n",
    "val_accuracy = final_rf_model.score(valEmb, y_val)\n",
    "\n",
    "print(f\"Exactitud en el conjunto de entrenamiento: {train_accuracy:.3f}\")\n",
    "print(f\"Exactitud en el conjunto de validación: {val_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-accuracy con el mejor modelo de Random Forest 76.89%\n",
      "\n",
      "Matriz de confusión con el mejor modelo de Random Forest:\n",
      "[[165  51]\n",
      " [ 53 181]]\n",
      "\n",
      "Matriz de confusión con el mejor modelo de Random Forest en proporciones:\n",
      "[[0.36666667 0.11333333]\n",
      " [0.11777778 0.40222222]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Test-accuracy con el mejor modelo de Random Forest %.2f%%' % (100*final_rf_model.score(testEmb, y_test)))\n",
    "\n",
    "pred = final_rf_model.predict(testEmb)\n",
    "print('\\nMatriz de confusión con el mejor modelo de Random Forest:')\n",
    "print(confusion_matrix(y_test, pred, labels=[0,1]))\n",
    "\n",
    "print('\\nMatriz de confusión con el mejor modelo de Random Forest en proporciones:')\n",
    "print(confusion_matrix(y_test, pred, labels=[0,1]) / pred.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vPKtRFMRXNH"
   },
   "source": [
    "Definición del Modelo y Rango Inicial de Hiperparámetros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "lKcqt3twRT9J"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definir rango inicial de hiperparámetros\n",
    "C_range = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "solver_options = ['lbfgs', 'liblinear', 'newton-cholesky', 'newton-cg', 'sag', 'saga']\n",
    "\n",
    "# Crear modelo inicial\n",
    "lr_model = LogisticRegression(penalty= 'l2', max_iter=5000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZsvjP9RRagD"
   },
   "source": [
    "Evaluación Manual de Diferentes Combinaciones de Hiperparámetros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "gVSQaK3GRa2K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 42 candidates, totalling 252 fits\n",
      "Mejor valor de exactitud obtenido con la mejor combinación: 0.79\n",
      "Mejor combinación de valores encontrados de los hiperparámetros: {'C': 10, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "lr_params= {'C': C_range, \n",
    "            'solver': solver_options}\n",
    "\n",
    "lr_grid= GridSearchCV(lr_model, lr_params, scoring='accuracy', cv=kfold, n_jobs=-1, verbose=3, error_score='raise')\n",
    "lr_grid.fit(trainEmb, y_train)\n",
    "lr_best = lr_grid.best_params_\n",
    "\n",
    "print(f'Mejor valor de exactitud obtenido con la mejor combinación: {round(lr_grid.best_score_,2)}')\n",
    "print(f'Mejor combinación de valores encontrados de los hiperparámetros: {lr_grid.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etxl8Ry4NpiI"
   },
   "source": [
    "Ajuste Final con GridSearchCV o RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "bXVuMYdFNqUG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud en el conjunto de entrenamiento: 0.845\n",
      "Exactitud en el conjunto de validación: 0.787\n"
     ]
    }
   ],
   "source": [
    "lr_best = lr_grid.best_params_\n",
    "\n",
    "final_lr_model = LogisticRegression(C=lr_best['C'], \n",
    "                                    solver=lr_best['solver'],\n",
    "                                    penalty= 'l2', max_iter=5000)\n",
    "final_lr_model.fit(trainEmb, y_train)\n",
    "train_accuracy = final_lr_model.score(trainEmb, y_train)\n",
    "val_accuracy = final_lr_model.score(valEmb, y_val)\n",
    "\n",
    "print(f\"Exactitud en el conjunto de entrenamiento: {train_accuracy:.3f}\")\n",
    "print(f\"Exactitud en el conjunto de validación: {val_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLmMyklBNwpm"
   },
   "source": [
    "Evaluación en el Conjunto de Prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "0mse2OZVNxor"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-accuracy con el mejor modelo de Logistic Regression 81.11%\n",
      "\n",
      "Matriz de confusión con el mejor modelo de Logistic Regression:\n",
      "[[165  51]\n",
      " [ 53 181]]\n",
      "\n",
      "Matriz de confusión con el mejor modelo de Logistic Regression en proporciones:\n",
      "[[0.36666667 0.11333333]\n",
      " [0.11777778 0.40222222]]\n"
     ]
    }
   ],
   "source": [
    "print('Test-accuracy con el mejor modelo de Logistic Regression %.2f%%' % (100*final_lr_model.score(testEmb, y_test)))\n",
    "\n",
    "pred = final_rf_model.predict(testEmb)\n",
    "print('\\nMatriz de confusión con el mejor modelo de Logistic Regression:')\n",
    "print(confusion_matrix(y_test, pred, labels=[0,1]))\n",
    "\n",
    "print('\\nMatriz de confusión con el mejor modelo de Logistic Regression en proporciones:')\n",
    "print(confusion_matrix(y_test, pred, labels=[0,1]) / pred.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcHKK4bIb2j-"
   },
   "source": [
    "*Se obtienen resultados similares a los obtenidos en la semana anterior. El modelo de regresión logística logra exactitudes por encima del 72% y el modelo de Bosques Aleatorios logra resultados similares y conserva su tendencia a sobreentrenarse. Para evitar lo anterios, se probaron varios métodos:*\n",
    "\n",
    "1. *Implementar validación cruzada.*\n",
    "2. *Reducir el número de estimadores.*\n",
    "\n",
    "*El primero no ayudó a reducir la tendencia a sobreentrenar el modelo. El seguno al reducirse a un valor de entr 2 y 10, logró con efectividad reducir el sobreentrenamiento. Sin embargo, la exactitud del conjunto de validación, también resultaba afectada negativamente, por lo tanto, se conservó el modelo sobreentrenado, ya que a pesar de esto, también logra los mejores resultados en el conjunto de validación. Entrenar el modelo con más datos, parece ser la mejor opción para lograr reducir el sobreentrenamiento en el modelo de bosques aleatorios.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3jy454oblEv"
   },
   "source": [
    "# **Pregunta 9**\n",
    "Obtener la matriz de confusión e interpretar sus valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nkibSchL_T_x"
   },
   "outputs": [],
   "source": [
    "def mi_cm(yreal, ypred):\n",
    "  cm = confusion_matrix(yreal, ypred)\n",
    "  txt = ['Verdaderos Negativos\\n(VN)','Falsos Positivos\\n(FP)',\\\n",
    "         'Falsos Negativos\\n(FN)', 'Verdaderos Positivos\\n(VP)']\n",
    "  frecuencia = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
    "  porcentaje = [\"{0:.1%}\".format(value) for value in cm.flatten()/np.sum(cm)]\n",
    "\n",
    "  labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(txt,frecuencia,porcentaje)]\n",
    "  labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "  ax = sns.heatmap(cm, annot=labels, fmt='', cmap='Spectral', cbar=False)\n",
    "  ax.set(ylabel=\"Etiquetas Reales\", xlabel=\"Etiquetas de Predicción\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RGlYDiAof3Wq"
   },
   "outputs": [],
   "source": [
    "#Se imprimen los resultados del conjunto de prueba y las matrices de confusión para cada modelo\n",
    "print('Test-accuracy con el mejor modelo de Regresión Logística: %.2f%%' % (100*modeloLRcount.score(testEmb, test_y)))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred1 = modeloLRcount.predict(testEmb)\n",
    "print('\\nMatriz de confusión con el mejor Regresión Logística:\\n')\n",
    "mi_cm(test_y, pred1)\n",
    "\n",
    "print('\\nTest-accuracy con el mejor modelo de Bosques Aleatorios: %.2f%%' % (100*modeloRFcount.score(testEmb, test_y)))\n",
    "print('\\nMatriz de confusión con el mejor Bosques Aleatorios:\\n')\n",
    "pred2 = modeloRFcount.predict(testEmb)\n",
    "mi_cm(test_y, pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QglSgTQkelAN"
   },
   "source": [
    "*Con relación a los resultados de las matrices de confusión por medio de ambos métodos, el modelo de bosques aleatorios obtuvo valor menor de clasificaciones verdaderas positivas, pero mayor en verdaderas negativas, logrando una cantidad neta de clasificaciones correctas mayor que el método de regresión logística. Se logró reducir el número de clasificaciones falsas negativas y se incrementó proporcionalmente el número falsos positivos. Al igual que lo descrito anteriormente, el valor neto clasificaciones incorrectas es menor que por el método de conteo. Lo anterior en resumen, implica que el método de bosques aleatorios es mejor para los algoritmos de clasificación, para diferenciar mejor las clases negativas en general que el método de conteo a cambio de una ligera degradación en la clasificación de clases positivas.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4CmKx0z6NNb"
   },
   "source": [
    "# **Pregunta 10**\n",
    "Comenta con tus compañeros de equipo los pasos realizados en esta actividad e incluyan sus conclusiones finales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGcUa5OhB_oP"
   },
   "source": [
    ">>> *Agregar aquí conclusiones del trabajo*\n",
    "\n",
    "*Dentro de la limpieza realizada se encontraron algunas validaciones que mejoraron el desempeño del modelo dado que no se procesaron ciertos valores o caracteres que no son relevantes para el estudio y alteran el resultado esperado. Posteriormente, se ejecutaron las particiones de los elementos para el desarrollo de los modelos; para ello, se acotaron los caracteres dentro del diccionario del conjunto de entrenamiento dado que se involucraron únicamente palabras relevantes las cuales tienen una mayor cantidad de frecuencia dentro de los datos.*\n",
    "\n",
    "*Luego del preprocesamiento anterior, se inició la validación del modelo **FastText** con el fin de identificar la relación que tienen las palabras que contiene el diccionario definido. Luego de inicializarlo, se desarrollaron las funciones requeridas para obtener el promedio de los vectores y de allí otra función que transforme los documentos a vectores embebidos con el fin de asignarles valores a los vectores e identificar la correlación de cada uno entre ellos.*\n",
    "\n",
    "*Con los procedimientos anteriores, se utilizaron dichos vectores para optimizar los modelos de Random Forest y Linear Regression, obteniendo su desempeño y la validación de estos. Detectando los hiperparámetros requeridos para cada modelo y obteniendo los resultados del desempeño de cada uno. **FastText** permite una mejor predicción dado que asigna una mejor relación entre las palabras que únicamente valores de 1 y 0 para los caracteres obtenidos, distorsionando el valor del desempeño de los modelos.*\n",
    "\n",
    "*Para este caso, el método de transformar el corpus a sus vectores preentrenados embebidos, después de el proceso de limpieza y lematización, para después calcular el promedio de los vectores para cada comentario, resultó en una desempeño menor que el que se obtuvo para el mismo conjunto de datos y el uso de la matriz dispersa por conteo de frecuencias y de tf-idf. Con lo anterior, se pudo comprender el valor de tener cada palabra representada como un elemento de un espacio vectorial para encontrar la relación entre las palabras cercanas, sin embargo, para este caso, el uso del promedio de dichos vectores no resultó superior en exactitud a los resultados logrados con las matrices dispersas. Posiblemente, los resultados se pueden mejorar si emplea una simplificación del comentario diferente al promedio de los vectores, como lo sería un proceso de reducción tomando en cuenta la relación que tiene una palabra con otra.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fK_RJaCNBEoj"
   },
   "source": [
    "##### **Fuentes bibliográficas y de datos:**\n",
    "- https://raw.githubusercontent.com/Handrum/NLP_EQ_6/main/amazon5.txt\n",
    "- https://raw.githubusercontent.com/Handrum/NLP_EQ_6/main/imdb5.txt\n",
    "- https://raw.githubusercontent.com/Handrum/NLP_EQ_6/main/yelp5.txt\n",
    "- https://fasttext.cc/\n",
    "- https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "- https://code.google.com/archive/p/word2vec/\n",
    "- https://nlp.stanford.edu/projects/glove/\n",
    "- https://medium.com/analytics-vidhya/word2vec-glove-fasttext-and-baseline-word-embeddings-step-by-step-d0489c15d10b\n",
    "\n",
    "- Vajjala, S., Majumder, B., Gupta, A., y Surana, H. (2020). Practical Natural Language Processing: A Comprehensive Guide to Building Real-World NLP Systems. O'Reilly. https://learning.oreilly.com/library/view/practical-natural-language/9781492054047/\n",
    "\n",
    "\n",
    "- Khurana, D., Koli, A., Khatter, K., y Singh, S. (2023). Natural language processing: state of the art, current trends and challenges. Multimed Tools Appl 82, 3713–3744. https://link.springer.com/article/10.1007/s11042-022-13428-4Links to an external site.\n",
    "\n",
    "- Falcón Morales, L. E. (2023). Bolsa de palabras: BOW [PDF]. Maestría en Inteligencia Artificial Aplicada. ITESM. Acceso al material Download Acceso al material"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
